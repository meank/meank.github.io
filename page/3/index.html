<!doctype html>
<html class="theme-next   use-motion ">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />












  <link href="/vendors/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css"/>




  <link href="//fonts.googleapis.com/css?family=Lato:300,400,700,400italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">



<link href="/vendors/font-awesome/css/font-awesome.min.css?v=4.4.0" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=0.4.5.2" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Hexo, NexT" />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=0.4.5.2" />






<meta name="description">
<meta property="og:type" content="website">
<meta property="og:title" content="Hexo">
<meta property="og:url" content="http://yoursite.com/page/3/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Hexo">
<meta name="twitter:description">



<script type="text/javascript" id="hexo.configuration">
  var CONFIG = {
    scheme: '',
    sidebar: 'post',
    motion: true
  };
</script>

  <title> Hexo </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="">

  <!--[if lte IE 8]>
  <div style=' clear: both; height: 59px; padding:0 0 0 15px; position: relative;margin:0 auto;'>
    <a href="http://windows.microsoft.com/en-US/internet-explorer/products/ie/home?ocid=ie6_countdown_bannercode">
      <img src="http://7u2nvr.com1.z0.glb.clouddn.com/picouterie.jpg" border="0" height="42" width="820"
           alt="You are using an outdated browser. For a faster, safer browsing experience, upgrade for free today or use other browser ,like chrome firefox safari."
           style='margin-left:auto;margin-right:auto;display: block;'/>
    </a>
  </div>
<![endif]-->
  






  <div class="container one-column 
   page-home 
">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-meta ">
  

  <div class="custom-logo-site-title">
    <a href="/"  class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <span class="site-title">Hexo</span>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>
  <p class="site-subtitle"></p>
</div>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu ">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-home fa-fw"></i> <br />
            
            首頁
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-archive fa-fw"></i> <br />
            
            歸檔
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-tags fa-fw"></i> <br />
            
            標籤
          </a>
        </li>
      

      
      
    </ul>
  

  
</nav>

 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div id="content" class="content">
          
  <section id="posts" class="posts-expand">

    

    
    

    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2015/10/04/NLP/deep-learning-for-nature-language-processing-e7-ac-ac-e5-9b-9b-e8-ae-b2-e4-b8-8a/" itemprop="url">
                  Deep Learning for Nature Language Processing---第四讲(上)
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            發表於
            <time itemprop="dateCreated" datetime="2015-10-04T19:42:49+08:00" content="2015-10-04">
              2015-10-04
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp; 分類於
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/NLP/" itemprop="url" rel="index">
                    <span itemprop="name">NLP</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

        </div>
      </header>
    


    <div class="post-body">

      
      

      
        
          <span itemprop="articleBody">
            
              <h1 id="u5206_u7C7B_u7684_u57FA_u7840_u77E5_u8BC6_u548C_u6807_u8BB0notation"><a href="#u5206_u7C7B_u7684_u57FA_u7840_u77E5_u8BC6_u548C_u6807_u8BB0notation" class="headerlink" title="<strong>分类的基础知识和标记notation</strong>"></a><strong>分类的基础知识和标记notation</strong></h1><h4 id="u91C7_u6837_u91C7_u96C6_u5230_u7684_u6570_u636E_u96C6_3A"><a href="#u91C7_u6837_u91C7_u96C6_u5230_u7684_u6570_u636E_u96C6_3A" class="headerlink" title="采样采集到的数据集:"></a>采样采集到的数据集:</h4><p><img src="http://img.blog.csdn.net/20150703211656490" alt="这里写图片描述"></p>
<h4 id="xi__u2014_u8F93_u5165-__u4F8B_u5982__3A_u5355_u8BCD_28_u6807_u53F7_u6216_u5411_u91CFvector_29_2Ccontext_windows_2C_u53E5_u5B50_2C_u6587_u6863_u7B49"><a href="#xi__u2014_u8F93_u5165-__u4F8B_u5982__3A_u5355_u8BCD_28_u6807_u53F7_u6216_u5411_u91CFvector_29_2Ccontext_windows_2C_u53E5_u5B50_2C_u6587_u6863_u7B49" class="headerlink" title="x<sub>i</sub>  —输入. 例如 :单词(标号或向量vector),context windows,句子,文档等."></a>x<sub>i</sub>  —输入. 例如 :单词(标号或向量vector),context windows,句子,文档等.</h4><h4 id="yi__u2014_u6807_u7B7E-__u4F8B_u5982_3A_u60C5_u611F_2C_u5176_u4ED6_u7684_u5355_u8BCD_2C_u547D_u540D_u5B9E_u4F53_28_u53C2_u7167NER_29_2C_u4E70_u5356_u51B3_u65AD_2C_u4EE5_u540E_u8FD8_u4F1A_u6D89_u53CA_u5230_3A_multi-_AD_u2010word_sequences"><a href="#yi__u2014_u6807_u7B7E-__u4F8B_u5982_3A_u60C5_u611F_2C_u5176_u4ED6_u7684_u5355_u8BCD_2C_u547D_u540D_u5B9E_u4F53_28_u53C2_u7167NER_29_2C_u4E70_u5356_u51B3_u65AD_2C_u4EE5_u540E_u8FD8_u4F1A_u6D89_u53CA_u5230_3A_multi-_AD_u2010word_sequences" class="headerlink" title="y<sub>i</sub>  —标签. 例如:情感,其他的单词,命名实体(参照NER),买卖决断,以后还会涉及到: multi-­‐word sequences"></a>y<sub>i</sub>  —标签. 例如:情感,其他的单词,命名实体(参照NER),买卖决断,以后还会涉及到: multi-­‐word sequences</h4><h1 id="u5206_u7C7B_intuition"><a href="#u5206_u7C7B_intuition" class="headerlink" title="<strong>分类 intuition</strong>"></a><strong>分类 intuition</strong></h1><h4 id="u8BAD_u7EC3_u96C6_3A_7Bxi_2Cyi_7DNi_3D1"><a href="#u8BAD_u7EC3_u96C6_3A_7Bxi_2Cyi_7DNi_3D1" class="headerlink" title="训练集:{x<sub>i</sub>,y<sub>i</sub>}<sup>N</sup><sub>i=1</sub>"></a>训练集:{x<sub>i</sub>,y<sub>i</sub>}<sup>N</sup><sub>i=1</sub></h4><h4 id="u7B80_u5355_u6A21_u578B_3A"><a href="#u7B80_u5355_u6A21_u578B_3A" class="headerlink" title="简单模型:"></a>简单模型:</h4><h5 id="1-_u5206_u7C7B_u56FA_u5B9A_u7684_u4E8C_u4F4Dword_vector"><a href="#1-_u5206_u7C7B_u56FA_u5B9A_u7684_u4E8C_u4F4Dword_vector" class="headerlink" title="1.分类固定的二位word vector"></a>1.分类固定的二位word vector</h5><h5 id="2-_u4F7F_u7528_u903B_u8F91_u56DE_u5F52_Logistic_Regression"><a href="#2-_u4F7F_u7528_u903B_u8F91_u56DE_u5F52_Logistic_Regression" class="headerlink" title="2.使用逻辑回归 Logistic Regression"></a>2.使用逻辑回归 Logistic Regression</h5><h5 id="3-_u793A_u610F_u56FE_u5982_u4E0B_28_u7EBF_u6027_u51B3_u7B56_u7EBFlinear_decision_boundary_29_3A"><a href="#3-_u793A_u610F_u56FE_u5982_u4E0B_28_u7EBF_u6027_u51B3_u7B56_u7EBFlinear_decision_boundary_29_3A" class="headerlink" title="3.示意图如下(线性决策线linear decision boundary):"></a>3.示意图如下(线性决策线linear decision boundary):</h5><p><img src="http://img.blog.csdn.net/20150703221354198" alt="这里写图片描述"></p>
<h4 id="u4E00_u822C_u60C5_u51B5_u4E0B_u7684ML_3A_u5047_u5B9Ax_u662F_u56FA_u5B9A_u7684_2C_u53EA_u8BAD_u7EC3_u903B_u8F91_u56DE_u5F52_u7684_u6743_u91CDW-_u5373_u4FEE_u6539decision_boundary_3A"><a href="#u4E00_u822C_u60C5_u51B5_u4E0B_u7684ML_3A_u5047_u5B9Ax_u662F_u56FA_u5B9A_u7684_2C_u53EA_u8BAD_u7EC3_u903B_u8F91_u56DE_u5F52_u7684_u6743_u91CDW-_u5373_u4FEE_u6539decision_boundary_3A" class="headerlink" title="一般情况下的ML:假定x是固定的,只训练逻辑回归的权重W.即修改decision boundary:<img src=" http:="" img.blog.csdn.net="" 20150703221815439"="" alt="这里写图片描述">"></a>一般情况下的ML:假定x是固定的,只训练逻辑回归的权重W.即修改decision boundary:<img src="http://img.blog.csdn.net/20150703221815439" alt="这里写图片描述"></h4><h4 id="u6570_u636E_u96C6_7Bxi_2Cyi_7DNi_3D1_u7684loss_function_3A"><a href="#u6570_u636E_u96C6_7Bxi_2Cyi_7DNi_3D1_u7684loss_function_3A" class="headerlink" title="数据集{x<sub>i</sub>,y<sub>i</sub>}<sup>N</sup><sub>i=1</sub>的loss function:"></a>数据集{x<sub>i</sub>,y<sub>i</sub>}<sup>N</sup><sub>i=1</sub>的loss function:</h4><p><img src="http://img.blog.csdn.net/20150703222021090" alt="这里写图片描述"><br>其中N为数据集的大小</p>
<h4 id="u5176_u4E2D_3A"><a href="#u5176_u4E2D_3A" class="headerlink" title="其中:"></a>其中:</h4><p><img src="http://img.blog.csdn.net/20150703222342323" alt="这里写图片描述"></p>
<h1 id="regularization"><a href="#regularization" class="headerlink" title="<strong>regularization</strong>"></a><strong>regularization</strong></h1><h4 id="regularization_u540E_u7684loss_function_3A"><a href="#regularization_u540E_u7684loss_function_3A" class="headerlink" title="regularization后的loss function:"></a>regularization后的loss function:</h4><p><img src="http://img.blog.csdn.net/20150703222829899" alt="这里写图片描述"></p>
<h4 id="u5F53_u6709_u975E_u5E38_u591A_u7684_u7279_u5F81features_u65F6_2C_u6216_u8005_u5BF9_u4E8E_u540E_u9762_u9700_u8981_u7528_u5230_u7684_u6DF1_u5EA6_u5B66_u4E60_u6A21_u578B_2Cregularization_u6709_u5229_u4E8E_u9632_u6B62overfitting"><a href="#u5F53_u6709_u975E_u5E38_u591A_u7684_u7279_u5F81features_u65F6_2C_u6216_u8005_u5BF9_u4E8E_u540E_u9762_u9700_u8981_u7528_u5230_u7684_u6DF1_u5EA6_u5B66_u4E60_u6A21_u578B_2Cregularization_u6709_u5229_u4E8E_u9632_u6B62overfitting" class="headerlink" title="当有非常多的特征features时,或者对于后面需要用到的深度学习模型,regularization有利于防止overfitting."></a>当有非常多的特征features时,或者对于后面需要用到的深度学习模型,regularization有利于防止overfitting.</h4><p><img src="http://img.blog.csdn.net/20150703223119039" alt="这里写图片描述"><br>其中x轴正向代表更多的迭代次数或者更”深”的模型,蓝线代表训练误差,红线代表测试误差test error.</p>
<h1 id="Classification_difference_with_word_vectors"><a href="#Classification_difference_with_word_vectors" class="headerlink" title="<strong>Classification difference with word  vectors</strong>"></a><strong>Classification difference with word  vectors</strong></h1><h4 id="u4E00_u822C_u7684_u673A_u5668_u5B66_u4E60_u6A21_u578B_u4E2D_2C_24_5Ctheta_24__u53EA_u5305_u62ECW_28_u6CE8_u610F_24_5Ctheta_24__u662F_u4E00_u4E2A_u5217_u5411_u91CF_29_3A"><a href="#u4E00_u822C_u7684_u673A_u5668_u5B66_u4E60_u6A21_u578B_u4E2D_2C_24_5Ctheta_24__u53EA_u5305_u62ECW_28_u6CE8_u610F_24_5Ctheta_24__u662F_u4E00_u4E2A_u5217_u5411_u91CF_29_3A" class="headerlink" title="一般的机器学习模型中,$\theta$ 只包括W(注意$\theta$ 是一个列向量):"></a>一般的机器学习模型中,$\theta$ 只包括W(注意$\theta$ 是一个列向量):</h4><p><img src="http://img.blog.csdn.net/20150703223937265" alt="这里写图片描述"></p>
<h4 id="u6240_u4EE5_u6211_u4EEC_u4EC5_u4EC5_u66F4_u65B0decision_boundary_3A"><a href="#u6240_u4EE5_u6211_u4EEC_u4EC5_u4EC5_u66F4_u65B0decision_boundary_3A" class="headerlink" title="所以我们仅仅更新decision boundary:"></a>所以我们仅仅更新decision boundary:</h4><p><img src="http://img.blog.csdn.net/20150703224111350" alt="这里写图片描述"></p>
<h4 id="u800C_u5BF9_u4E8E_u8981_u8BAD_u7EC3_u6743_u503CW_u548CX_28word_vector_29_u7684_u6A21_u578B_2C_u65E2_u8981_u66F4_u65B0word_vector_2C_u4E5F_u8981_u66F4_u65B0decision_boundary_3A"><a href="#u800C_u5BF9_u4E8E_u8981_u8BAD_u7EC3_u6743_u503CW_u548CX_28word_vector_29_u7684_u6A21_u578B_2C_u65E2_u8981_u66F4_u65B0word_vector_2C_u4E5F_u8981_u66F4_u65B0decision_boundary_3A" class="headerlink" title="而对于要训练权值W和X(word vector)的模型,既要更新word vector,也要更新decision boundary:"></a>而对于要训练权值W和X(word vector)的模型,既要更新word vector,也要更新decision boundary:</h4><p><img src="http://img.blog.csdn.net/20150703224315707" alt="这里写图片描述"></p>
<h1 id="Loosing_generalization_by_re-_AD_u2010training_word_vectors_28_u5E94_u8BE5_u662F_u8BAD_u7EC3word_vector_u4F1A_u5931_u53BB_u6A21_u578B_u7684_u6CDB_u5316_u7279_u6027_u7684_u610F_u601D_29"><a href="#Loosing_generalization_by_re-_AD_u2010training_word_vectors_28_u5E94_u8BE5_u662F_u8BAD_u7EC3word_vector_u4F1A_u5931_u53BB_u6A21_u578B_u7684_u6CDB_u5316_u7279_u6027_u7684_u610F_u601D_29" class="headerlink" title="<strong>Loosing generalization by re-­‐training word vectors(应该是训练word vector会失去模型的泛化特性的意思)</strong>"></a><strong>Loosing generalization by re-­‐training word vectors(应该是训练word vector会失去模型的泛化特性的意思)</strong></h1><h4 id="u793A_u4F8B_3A_u8BAD_u7EC3_u7535_u5F71_u8BC4_u8BBA_u60C5_u611F_u7684_u903B_u8F91_u56DE_u5F52_u6A21_u578B_3A"><a href="#u793A_u4F8B_3A_u8BAD_u7EC3_u7535_u5F71_u8BC4_u8BBA_u60C5_u611F_u7684_u903B_u8F91_u56DE_u5F52_u6A21_u578B_3A" class="headerlink" title="示例:训练电影评论情感的逻辑回归模型:"></a>示例:训练电影评论情感的逻辑回归模型:</h4><h5 id="1-_u5728_u8BAD_u7EC3_u96C6_u4E2D_2C_u6709_u201DTV_u201D_u548C_u201Dtelly_u201D-_u6D4B_u8BD5_u96C6_u4E2D_u6709_u201Dtelevision_u201D"><a href="#1-_u5728_u8BAD_u7EC3_u96C6_u4E2D_2C_u6709_u201DTV_u201D_u548C_u201Dtelly_u201D-_u6D4B_u8BD5_u96C6_u4E2D_u6709_u201Dtelevision_u201D" class="headerlink" title="1.在训练集中,有”TV”和”telly”.测试集中有”television”"></a>1.在训练集中,有”TV”和”telly”.测试集中有”television”</h5><h5 id="2-_u521D_u59CB_u8BBE_u7F6E_28pre-training_29_u7684word_vectors_u5982_u56FE_3A"><a href="#2-_u521D_u59CB_u8BBE_u7F6E_28pre-training_29_u7684word_vectors_u5982_u56FE_3A" class="headerlink" title="2.初始设置(pre-training)的word vectors如图:"></a>2.初始设置(pre-training)的word vectors如图:</h5><p><img src="http://img.blog.csdn.net/20150704095808185" alt="这里写图片描述"></p>
<h5 id="3-_u4F46_u662F_u5728_u8BAD_u7EC3_u4E4B_u540E_3A"><a href="#3-_u4F46_u662F_u5728_u8BAD_u7EC3_u4E4B_u540E_3A" class="headerlink" title="3.但是在训练之后:"></a>3.但是在训练之后:</h5><p><img src="http://img.blog.csdn.net/20150704095927410" alt="这里写图片描述"></p>
<h4 id="u4ECE_u4EE5_u4E0A_u4E24_u5F20_u56FE_u4E2D_u53EF_u4EE5_u53D1_u73B0_3A_u8BAD_u7EC3_u96C6trainning_set_u4E2D_u7684word_vectors_u5DF2_u7ECF_u53D1_u751F_u4E86_u6539_u53D8-_u603B_u7ED3_u51FA_u4E24_u4E2A_u6280_u5DE7_3A1-_u82E5_u8BAD_u7EC3_u96C6_u5C0F_2C_u4E0D_u8981_u8BAD_u7EC3word_vectors-2-_u82E5_u8BAD_u7EC3_u96C6_u8DB3_u591F_u5927_2C_u6700_u597D_u4E5F_u8BAD_u7EC3word_vectors"><a href="#u4ECE_u4EE5_u4E0A_u4E24_u5F20_u56FE_u4E2D_u53EF_u4EE5_u53D1_u73B0_3A_u8BAD_u7EC3_u96C6trainning_set_u4E2D_u7684word_vectors_u5DF2_u7ECF_u53D1_u751F_u4E86_u6539_u53D8-_u603B_u7ED3_u51FA_u4E24_u4E2A_u6280_u5DE7_3A1-_u82E5_u8BAD_u7EC3_u96C6_u5C0F_2C_u4E0D_u8981_u8BAD_u7EC3word_vectors-2-_u82E5_u8BAD_u7EC3_u96C6_u8DB3_u591F_u5927_2C_u6700_u597D_u4E5F_u8BAD_u7EC3word_vectors" class="headerlink" title="从以上两张图中可以发现:训练集trainning set中的word vectors已经发生了改变.总结出两个技巧:1.若训练集小,不要训练word vectors.2.若训练集足够大,最好也训练word vectors."></a>从以上两张图中可以发现:训练集trainning set中的word vectors已经发生了改变.总结出两个技巧:1.若训练集小,不要训练word vectors.2.若训练集足够大,最好也训练word vectors.</h4><h1 id="u8BFE_u4EF6_u4E0A_u5173_u4E8Eword_vectors_u7684_u4E00_u4E9B_u6807_u8BB0notation"><a href="#u8BFE_u4EF6_u4E0A_u5173_u4E8Eword_vectors_u7684_u4E00_u4E9B_u6807_u8BB0notation" class="headerlink" title="<strong>课件上关于word vectors的一些标记notation</strong>"></a><strong>课件上关于word vectors的一些标记notation</strong></h1><h4 id="word_vectors_u77E9_u9635L_u4E5F_u53EB_u4F5Clook-up_table"><a href="#word_vectors_u77E9_u9635L_u4E5F_u53EB_u4F5Clook-up_table" class="headerlink" title="word vectors矩阵L也叫作look-up table"></a>word vectors矩阵L也叫作look-up table</h4><h4 id="Word_vectors__3D_word_embeddings__3D_word_representations__28mostly_29"><a href="#Word_vectors__3D_word_embeddings__3D_word_representations__28mostly_29" class="headerlink" title="Word   vectors =   word embeddings = word representations (mostly)"></a>Word   vectors =   word embeddings = word representations (mostly)</h4><p><img src="http://img.blog.csdn.net/20150704101140406" alt="这里写图片描述"></p>
<h4 id="u56FE_u7247_u4E0A_u7684_u6807_u8BB0notation_u5927_u591A_u6765_u81EAword2vec_u6216_u8005glove_2C_u4ECE_u73B0_u5728_u5F00_u59CB_u7528xword_28words_feature_29_u7C7B_u4F3C_u7684_u6807_u8BB0_u8868_u793A"><a href="#u56FE_u7247_u4E0A_u7684_u6807_u8BB0notation_u5927_u591A_u6765_u81EAword2vec_u6216_u8005glove_2C_u4ECE_u73B0_u5728_u5F00_u59CB_u7528xword_28words_feature_29_u7C7B_u4F3C_u7684_u6807_u8BB0_u8868_u793A" class="headerlink" title="图片上的标记notation大多来自word2vec或者glove,从现在开始用x<sub>word</sub>(words feature)类似的标记表示."></a>图片上的标记notation大多来自word2vec或者glove,从现在开始用x<sub>word</sub>(words feature)类似的标记表示.</h4><h4 id="word_vectors_u77E9_u9635L_u901A_u8FC7_u4E0E_u4E00_u4E2Aone-hot_u5411_u91CF_u76F8_u4E58_u5F97_u5230_u4E00_u4E2Aword_u2019s_vector_3A_x__3D_Le__28L_u4E3Ad_V_u77E9_u9635_2Ce_u4E3AV_1_u5411_u91CF_29"><a href="#word_vectors_u77E9_u9635L_u901A_u8FC7_u4E0E_u4E00_u4E2Aone-hot_u5411_u91CF_u76F8_u4E58_u5F97_u5230_u4E00_u4E2Aword_u2019s_vector_3A_x__3D_Le__28L_u4E3Ad_V_u77E9_u9635_2Ce_u4E3AV_1_u5411_u91CF_29" class="headerlink" title="word vectors矩阵L通过与一个one-hot向量相乘得到一个word’s vector: x = Le   (L为d_V矩阵,e为V_1向量)"></a>word vectors矩阵L通过与一个one-hot向量相乘得到一个word’s vector: x = Le   (L为d_V矩阵,e为V_1向量)</h4><h1 id="Window_classification_28_u57FA_u4E8Econtext_window_u7684_u5206_u7C7B_29"><a href="#Window_classification_28_u57FA_u4E8Econtext_window_u7684_u5206_u7C7B_29" class="headerlink" title="<strong>Window  classification(基于context window的分类)</strong>"></a><strong>Window  classification(基于context window的分类)</strong></h1><h4 id="u4E3B_u8981_u601D_u60F3_3A_u4E0D_u540C_u4E0E_u53EA_u5BF9_u5355_u4E2A_u5355_u8BCD_u5206_u7C7B_2Cwindow_classification_u901A_u8FC7_u7ED9_u67D0_u4E2A_u5355_u8BCD_u5468_u56F4_u7684_u8BCD_u8FDB_u884C_u52A0_u7A97_u5904_u7406_2C_u7136_u540E_u662F_u5206_u7C7B_u8FD9_u4E2A_u5355_u8BCD"><a href="#u4E3B_u8981_u601D_u60F3_3A_u4E0D_u540C_u4E0E_u53EA_u5BF9_u5355_u4E2A_u5355_u8BCD_u5206_u7C7B_2Cwindow_classification_u901A_u8FC7_u7ED9_u67D0_u4E2A_u5355_u8BCD_u5468_u56F4_u7684_u8BCD_u8FDB_u884C_u52A0_u7A97_u5904_u7406_2C_u7136_u540E_u662F_u5206_u7C7B_u8FD9_u4E2A_u5355_u8BCD" class="headerlink" title="主要思想:不同与只对单个单词分类,window classification通过给某个单词周围的词进行加窗处理,然后是分类这个单词"></a>主要思想:不同与只对单个单词分类,window classification通过给某个单词周围的词进行加窗处理,然后是分类这个单词</h4><h4 id="u6709_u4E00_u4E9B_u52A0_u7A97_u5206_u7C7B_u7684_u65B9_u6CD5-_u4F8B_u5982_3A_u5BF9_u7A97_u53E3_u91CC_u7684_u6240_u6709word_vector_u53D6_u5E73_u5747_2C_u503C_2C_u5355_u8FD9_u6837_u4F1A_u4E22_u5931_u5FC5_u8981_u7684_u5355_u8BCD_u6240_u5728_u53E5_u5B50_u7684_u4F4D_u7F6E_u4FE1_u606F"><a href="#u6709_u4E00_u4E9B_u52A0_u7A97_u5206_u7C7B_u7684_u65B9_u6CD5-_u4F8B_u5982_3A_u5BF9_u7A97_u53E3_u91CC_u7684_u6240_u6709word_vector_u53D6_u5E73_u5747_2C_u503C_2C_u5355_u8FD9_u6837_u4F1A_u4E22_u5931_u5FC5_u8981_u7684_u5355_u8BCD_u6240_u5728_u53E5_u5B50_u7684_u4F4D_u7F6E_u4FE1_u606F" class="headerlink" title="有一些加窗分类的方法.例如:对窗口里的所有word vector取平均,值,单这样会丢失必要的单词所在句子的位置信息."></a>有一些加窗分类的方法.例如:对窗口里的所有word vector取平均,值,单这样会丢失必要的单词所在句子的位置信息.</h4><h4 id="idea_3A_u4EE5_u4E0B_u56FE_u7684_u53E5_u5B50_u4E3A_u4F8B_3A_u7ED9_u4E00_u4E2A_u53E5_u5B50_u7684_u6700_u4E2D_u95F4_u7684_u8BCD_u9644_u4E0A_u6807_u7B7Elabel-_u7136_u540E_u5C06_u4E4B_u4E0E_u5468_u56F4_u5355_u8BCD_u7684word_vector_u8054_u7CFB_u8D77_u6765_2C_u7EC4_u6210_u4E00_u4E2A_u6BD4xParis_u7EF4_u5EA6_u66F4_u9AD8_u7684_u7684_u5217_u5411_u91CFxwindow_28_u6CE8_u610F_u662F_u4E00_u4E2A_u5217_u5411_u91CF_29_3A"><a href="#idea_3A_u4EE5_u4E0B_u56FE_u7684_u53E5_u5B50_u4E3A_u4F8B_3A_u7ED9_u4E00_u4E2A_u53E5_u5B50_u7684_u6700_u4E2D_u95F4_u7684_u8BCD_u9644_u4E0A_u6807_u7B7Elabel-_u7136_u540E_u5C06_u4E4B_u4E0E_u5468_u56F4_u5355_u8BCD_u7684word_vector_u8054_u7CFB_u8D77_u6765_2C_u7EC4_u6210_u4E00_u4E2A_u6BD4xParis_u7EF4_u5EA6_u66F4_u9AD8_u7684_u7684_u5217_u5411_u91CFxwindow_28_u6CE8_u610F_u662F_u4E00_u4E2A_u5217_u5411_u91CF_29_3A" class="headerlink" title="idea:以下图的句子为例:给一个句子的最中间的词附上标签label.然后将之与周围单词的word vector联系起来,组成一个比x<sub>Paris</sub>维度更高的的列向量x<sub>window</sub>(注意是一个列向量):"></a>idea:以下图的句子为例:给一个句子的最中间的词附上标签label.然后将之与周围单词的word vector联系起来,组成一个比x<sub>Paris</sub>维度更高的的列向量x<sub>window</sub>(注意是一个列向量):</h4><p><img src="http://img.blog.csdn.net/20150704104423560" alt="这里写图片描述"></p>
<h1 id="Simplest_window_classifer_3ASoftmax_28_u6700_u7B80_u5355_u7684_u52A0_u7A97_u5206_u7C7B_3Asoftmax_29"><a href="#Simplest_window_classifer_3ASoftmax_28_u6700_u7B80_u5355_u7684_u52A0_u7A97_u5206_u7C7B_3Asoftmax_29" class="headerlink" title="<strong>Simplest window classifer:Softmax(最简单的加窗分类:softmax)</strong>"></a><strong>Simplest window classifer:Softmax(最简单的加窗分类:softmax)</strong></h1><h4 id="u548C_u4EE5_u524D_u7528_u7684softmax_u4E00_u6837_2C_u4EE4x_3Dxwindow_u5373_u53EF_3A"><a href="#u548C_u4EE5_u524D_u7528_u7684softmax_u4E00_u6837_2C_u4EE4x_3Dxwindow_u5373_u53EF_3A" class="headerlink" title="和以前用的softmax一样,令x=x<sub>window</sub>即可:"></a>和以前用的softmax一样,令x=x<sub>window</sub>即可:</h4><p><img src="http://img.blog.csdn.net/20150704104741502" alt="这里写图片描述"></p>
<h1 id="Updating_concatenated_word_vectors"><a href="#Updating_concatenated_word_vectors" class="headerlink" title="<strong>Updating concatenated   word vectors</strong>"></a><strong>Updating concatenated   word vectors</strong></h1><h4 id="u6807_u8BB0_3A"><a href="#u6807_u8BB0_3A" class="headerlink" title="标记:"></a>标记:</h4><p><img src="http://img.blog.csdn.net/20150704110546130" alt="这里写图片描述"></p>
<h4 id="u4E00_u4E9B_u6280_u5DE7_3A"><a href="#u4E00_u4E9B_u6280_u5DE7_3A" class="headerlink" title="一些技巧:"></a>一些技巧:</h4><h5 id="1-_u8BA4_u771F_u7684_u5B9A_u4E49_u53D8_u91CF_2C_u5E76_u4E14_u65F6_u523B_u6CE8_u610F_u5176_u7EF4_u5EA6"><a href="#1-_u8BA4_u771F_u7684_u5B9A_u4E49_u53D8_u91CF_2C_u5E76_u4E14_u65F6_u523B_u6CE8_u610F_u5176_u7EF4_u5EA6" class="headerlink" title="1.认真的定义变量,并且时刻注意其维度"></a>1.认真的定义变量,并且时刻注意其维度</h5><h5 id="2-_u8BB0_u4F4F_u8FDE_u9501_u6548_u5E94_3A"><a href="#2-_u8BB0_u4F4F_u8FDE_u9501_u6548_u5E94_3A" class="headerlink" title="2.记住连锁效应:"></a>2.记住连锁效应:</h5><p><img src="http://img.blog.csdn.net/20150704110909904" alt="这里写图片描述"></p>
<h5 id="3-_u5728_u5BF9softmax_u8FDB_u884C_u6C42_u5BFC_u65F6_2C_u5148_u8BA1_u7B97_u8BE5_u8F93_u5165_u5BF9_u5E94_u7684_u6B63_u786E_u7C7B_u522B_u7684_u5012_u6570_2C_u5728_u8BA1_u7B97_u5176_u4ED6_u7C7B_u522B_u7684_u5012_u6570"><a href="#3-_u5728_u5BF9softmax_u8FDB_u884C_u6C42_u5BFC_u65F6_2C_u5148_u8BA1_u7B97_u8BE5_u8F93_u5165_u5BF9_u5E94_u7684_u6B63_u786E_u7C7B_u522B_u7684_u5012_u6570_2C_u5728_u8BA1_u7B97_u5176_u4ED6_u7C7B_u522B_u7684_u5012_u6570" class="headerlink" title="3.在对softmax进行求导时,先计算该输入对应的正确类别的倒数,在计算其他类别的倒数."></a>3.在对softmax进行求导时,先计算该输入对应的正确类别的倒数,在计算其他类别的倒数.</h5><h5 id="4-_u8BD5_u7740_u4E00_u6B21_u6027_u5BF9_u6240_u6709_u7C7B_u522B_u6C42_u5BFC"><a href="#4-_u8BD5_u7740_u4E00_u6B21_u6027_u5BF9_u6240_u6709_u7C7B_u522B_u6C42_u5BFC" class="headerlink" title="4.试着一次性对所有类别求导"></a>4.试着一次性对所有类别求导</h5><h5 id="5-_u5B66_u4F1A_u81EA_u5DF1_u5B9A_u4E49_u65B0_u53D8_u91CF_2C_u5BF9_u4EE5_u540E_u7684_u8FD0_u7B97_u5F88_u6709_u7528_3A"><a href="#5-_u5B66_u4F1A_u81EA_u5DF1_u5B9A_u4E49_u65B0_u53D8_u91CF_2C_u5BF9_u4EE5_u540E_u7684_u8FD0_u7B97_u5F88_u6709_u7528_3A" class="headerlink" title="5.学会自己定义新变量,对以后的运算很有用:"></a>5.学会自己定义新变量,对以后的运算很有用:</h5><p><img src="http://img.blog.csdn.net/20150704111723083" alt="这里写图片描述"><br><img src="http://img.blog.csdn.net/20150704111855884" alt="这里写图片描述"></p>
<h5 id="6-_u5411_u91CF_u5316_3A"><a href="#6-_u5411_u91CF_u5316_3A" class="headerlink" title="6.向量化:"></a>6.向量化:</h5><p><img src="http://img.blog.csdn.net/20150704111958607" alt="这里写图片描述"></p>
<h6 id="7-_u4E00_u4E2A_u7B80_u5355_u7684_u4F8B_u5B50_3A_u4E0B_u9762_u8FD0_u7B97_u540E_u7ED3_u679C_u7684_u7EF4_u6570_u662F_u591A_u5C11_3F"><a href="#7-_u4E00_u4E2A_u7B80_u5355_u7684_u4F8B_u5B50_3A_u4E0B_u9762_u8FD0_u7B97_u540E_u7ED3_u679C_u7684_u7EF4_u6570_u662F_u591A_u5C11_3F" class="headerlink" title="7.一个简单的例子:下面运算后结果的维数是多少?"></a>7.一个简单的例子:下面运算后结果的维数是多少?</h6><p><img src="http://img.blog.csdn.net/20150704112403536" alt="这里写图片描述"></p>
<h5 id="u56E0_u4E3Ax_u662F_u4E00_u4E2A5_d*d_u7684_u5217_u5411_u91CF_28d_u4E3Aword_vector_u7684_u7EF4_u6570_2C_u53C2_u89C1_u52A0_u7A97_u5904_u7406_u90E8_u5206_u7684word_vectors_u77E9_u9635L_29_2C_u6240_u4EE5_u5BF9x_u8FDB_u884C_u6C42_u5BFC_u540E_2C_u7ED3_u679C_u7684_u7EF4_u6570_u7B49_u4E8Ex_u7684_u7EF4_u6570"><a href="#u56E0_u4E3Ax_u662F_u4E00_u4E2A5_d*d_u7684_u5217_u5411_u91CF_28d_u4E3Aword_vector_u7684_u7EF4_u6570_2C_u53C2_u89C1_u52A0_u7A97_u5904_u7406_u90E8_u5206_u7684word_vectors_u77E9_u9635L_29_2C_u6240_u4EE5_u5BF9x_u8FDB_u884C_u6C42_u5BFC_u540E_2C_u7ED3_u679C_u7684_u7EF4_u6570_u7B49_u4E8Ex_u7684_u7EF4_u6570" class="headerlink" title="因为x是一个5 d*d的列向量(d为word vector的维数,参见加窗处理部分的word vectors矩阵L),所以对x进行求导后,结果的维数等于x的维数."></a>因为x是一个5 d*d的列向量(d为word vector的维数,参见加窗处理部分的word vectors矩阵L),所以对x进行求导后,结果的维数等于x的维数.</h5><h4 id="u5BF9context_window_u91CC_u7684_u6240_u6709_u5355_u8BCD_u7684word_vector_u8FDB_u884C_u6C42_u5BFC_2C_u53EF_u4EE5_u770B_u6210_u662F_u5BF9_u6BCF_u4E2A_u8BCD_u7684word_vector_u6C42_u5BFC_u7684_u7EC4_u5408_3A"><a href="#u5BF9context_window_u91CC_u7684_u6240_u6709_u5355_u8BCD_u7684word_vector_u8FDB_u884C_u6C42_u5BFC_2C_u53EF_u4EE5_u770B_u6210_u662F_u5BF9_u6BCF_u4E2A_u8BCD_u7684word_vector_u6C42_u5BFC_u7684_u7EC4_u5408_3A" class="headerlink" title="对context window里的所有单词的word vector进行求导,可以看成是对每个词的word vector求导的组合:"></a>对context window里的所有单词的word vector进行求导,可以看成是对每个词的word vector求导的组合:</h4><p><img src="http://img.blog.csdn.net/20150704113228938" alt="这里写图片描述"></p>
<h4 id="u52A0_u7A97_u7684_u65B9_u6CD5_u4F1A_u5E2E_u52A9_u6211_u4EEC_u51B3_u65AD_u547D_u540D_u5B9E_u4F53_u3002_u6BD4_u5982_u5BF9_u4E8E_u53E5_u5B50_uFF1A_u201Cmuseums_in_Paris_are_amazing_u201D_uFF0C_u6211_u4EEC_u5C31_u80FD_u5B66_u4E60_u5230in_u540E_u9762_u53EF_u80FD_u662F_u4E00_u4E2Alocation_u3002"><a href="#u52A0_u7A97_u7684_u65B9_u6CD5_u4F1A_u5E2E_u52A9_u6211_u4EEC_u51B3_u65AD_u547D_u540D_u5B9E_u4F53_u3002_u6BD4_u5982_u5BF9_u4E8E_u53E5_u5B50_uFF1A_u201Cmuseums_in_Paris_are_amazing_u201D_uFF0C_u6211_u4EEC_u5C31_u80FD_u5B66_u4E60_u5230in_u540E_u9762_u53EF_u80FD_u662F_u4E00_u4E2Alocation_u3002" class="headerlink" title="加窗的方法会帮助我们决断命名实体。比如对于句子：“museums in Paris are amazing”，我们就能学习到in后面可能是一个location。"></a>加窗的方法会帮助我们决断命名实体。比如对于句子：“museums in Paris are amazing”，我们就能学习到in后面可能是一个location。</h4>
            
          </span>
        
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2015/10/04/NLP/deep-learning-for-nature-language-processing-e7-ac-ac-e4-b8-89-e8-ae-b2/" itemprop="url">
                  Deep Learning for Nature Language Processing --- 第三讲
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            發表於
            <time itemprop="dateCreated" datetime="2015-10-04T19:42:03+08:00" content="2015-10-04">
              2015-10-04
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp; 分類於
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/NLP/" itemprop="url" rel="index">
                    <span itemprop="name">NLP</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

        </div>
      </header>
    


    <div class="post-body">

      
      

      
        
          <span itemprop="articleBody">
            
              <h3 id="u590D_u4E60_uFF1A_u7B80_u5355_u7684word2vec_u6A21_u578B"><a href="#u590D_u4E60_uFF1A_u7B80_u5355_u7684word2vec_u6A21_u578B" class="headerlink" title="<strong>复习：简单的word2vec模型</strong>"></a><strong>复习：简单的word2vec模型</strong></h3><h4 id="cost_fuction_uFF08__u6C42_u5BFC_u7ED3_u679C_u53C2_u7167_u89C6_u9891_u6559_u7A0B_uFF09_uFF1A"><a href="#cost_fuction_uFF08__u6C42_u5BFC_u7ED3_u679C_u53C2_u7167_u89C6_u9891_u6559_u7A0B_uFF09_uFF1A" class="headerlink" title="cost fuction（ 求导结果参照视频教程）："></a>cost fuction（ 求导结果参照视频教程）：</h4><p><img src="http://img.blog.csdn.net/20150702194845730" alt=""><br> <img src="http://img.blog.csdn.net/20150702195040758" alt="这里写图片描述"></p>
<h3 id="u68AF_u5EA6_u4E0B_u964D"><a href="#u68AF_u5EA6_u4E0B_u964D" class="headerlink" title="<strong>梯度下降</strong>"></a><strong>梯度下降</strong></h3><h4 id="u5C06_u6240_u6709_u53C2_u6570_u8F6C_u6362_u6210_u4E00_u4E2A_u5217_u5411_u91CF_24_5CTheta_24_uFF08V_u4E3A_u8BCD_u6C47_u6570_uFF0Cv_u662F_u4E2D_u5FC3_u8BCD_u7684word_vector_uFF0Cv_u2019_u662Fexternal_word_vector_uFF09_uFF1A"><a href="#u5C06_u6240_u6709_u53C2_u6570_u8F6C_u6362_u6210_u4E00_u4E2A_u5217_u5411_u91CF_24_5CTheta_24_uFF08V_u4E3A_u8BCD_u6C47_u6570_uFF0Cv_u662F_u4E2D_u5FC3_u8BCD_u7684word_vector_uFF0Cv_u2019_u662Fexternal_word_vector_uFF09_uFF1A" class="headerlink" title="将所有参数转换成一个列向量$\Theta$（V为词汇数，v是中心词的word vector，v’是external word vector）："></a>将所有参数转换成一个列向量$\Theta$（V为词汇数，v是中心词的word vector，v’是external word vector）：</h4><p><img src="http://img.blog.csdn.net/20150702200344048" alt="这里写图片描述"></p>
<h4 id="u4F7F_u7528full_batch_u6700_u5C0F_u5316cost_u5C06_u8981_u6C42_u8BA1_u7B97cost_u5BF9_u6240_u6709window_u7684_u5BFC_u6570"><a href="#u4F7F_u7528full_batch_u6700_u5C0F_u5316cost_u5C06_u8981_u6C42_u8BA1_u7B97cost_u5BF9_u6240_u6709window_u7684_u5BFC_u6570" class="headerlink" title="使用full batch最小化cost将要求计算cost对所有window的导数"></a>使用full batch最小化cost将要求计算cost对所有window的导数</h4><h4 id="u66F4_u65B0_24_5CTheta_24_u7684_u6BCF_u4E2A_u5143_u7D20_uFF1A"><a href="#u66F4_u65B0_24_5CTheta_24_u7684_u6BCF_u4E2A_u5143_u7D20_uFF1A" class="headerlink" title="更新$\Theta$的每个元素："></a>更新$\Theta$的每个元素：</h4><p><img src="http://img.blog.csdn.net/20150702200943519" alt="这里写图片描述"></p>
<h4 id="u5411_u91CF_u5316_u8868_u793A_uFF08_u5BF9_24_5CTheta_24_u4E2D_u7684_u6240_u6709_u5143_u7D20_uFF09_uFF1A"><a href="#u5411_u91CF_u5316_u8868_u793A_uFF08_u5BF9_24_5CTheta_24_u4E2D_u7684_u6240_u6709_u5143_u7D20_uFF09_uFF1A" class="headerlink" title="向量化表示（对$\Theta$中的所有元素）："></a>向量化表示（对$\Theta$中的所有元素）：</h4><p><img src="http://img.blog.csdn.net/20150702201117460" alt="这里写图片描述"></p>
<h4 id="u4EE3_u7801_u793A_u4F8B_uFF1A"><a href="#u4EE3_u7801_u793A_u4F8B_uFF1A" class="headerlink" title="代码示例："></a>代码示例：</h4><p><img src="http://img.blog.csdn.net/20150702201345199" alt="这里写图片描述"></p>
<h3 id="SGD"><a href="#SGD" class="headerlink" title="<strong>SGD</strong>"></a><strong>SGD</strong></h3><h4 id="u6570_u636E_u96C6_u53EF_u80FD_u542B_u670940B_u7684_u6570_u636E_uFF0C_u8FD9_u6837_u7684_u8BDD_uFF0C_u7528full_batch_u7684_u65B9_u6CD5_u5C31_u7B97_u8FED_u4EE3_u4E00_u6B21_u4E5F_u4F1A_u82B1_u8D39_u5F88_u957F_u65F6_u95F4_uFF0C_u6240_u4EE5_u91C7_u7528SGD_u7684_u65B9_u6CD5_uFF1A"><a href="#u6570_u636E_u96C6_u53EF_u80FD_u542B_u670940B_u7684_u6570_u636E_uFF0C_u8FD9_u6837_u7684_u8BDD_uFF0C_u7528full_batch_u7684_u65B9_u6CD5_u5C31_u7B97_u8FED_u4EE3_u4E00_u6B21_u4E5F_u4F1A_u82B1_u8D39_u5F88_u957F_u65F6_u95F4_uFF0C_u6240_u4EE5_u91C7_u7528SGD_u7684_u65B9_u6CD5_uFF1A" class="headerlink" title="数据集可能含有40B的数据，这样的话，用full batch的方法就算迭代一次也会花费很长时间，所以采用SGD的方法："></a>数据集可能含有40B的数据，这样的话，用full batch的方法就算迭代一次也会花费很长时间，所以采用SGD的方法：</h4><p><img src="http://img.blog.csdn.net/20150702201957120" alt="这里写图片描述"></p>
<h4 id="u4F46_u662F_u8FD8_u6709_u4E00_u4E2A_u95EE_u9898_uFF0C_u5728_u6BCF_u4E00_u4E2Awindow_u4E2D_u6700_u591A_u542B_u6709_uFF082c-1_uFF09_u4E2A_u5355_u8BCD_uFF08_u5373vector_uFF0C_u4E00_u4E2A_u5355_u8BCD_u5BF9_u5E94_u4E00_u4E2Avector_uFF09_uFF0C_u6240_u4EE5_u5F97_u5230_u7684cost_u5BF9_u6BCF_u4E2Awindow_u7684_u5BFC_u6570_u662F_u975E_u5E38_u7A00_u758F_u7684__uFF1A"><a href="#u4F46_u662F_u8FD8_u6709_u4E00_u4E2A_u95EE_u9898_uFF0C_u5728_u6BCF_u4E00_u4E2Awindow_u4E2D_u6700_u591A_u542B_u6709_uFF082c-1_uFF09_u4E2A_u5355_u8BCD_uFF08_u5373vector_uFF0C_u4E00_u4E2A_u5355_u8BCD_u5BF9_u5E94_u4E00_u4E2Avector_uFF09_uFF0C_u6240_u4EE5_u5F97_u5230_u7684cost_u5BF9_u6BCF_u4E2Awindow_u7684_u5BFC_u6570_u662F_u975E_u5E38_u7A00_u758F_u7684__uFF1A" class="headerlink" title="但是还有一个问题，在每一个window中最多含有（2c-1）个单词（即vector，一个单词对应一个vector），所以得到的cost对每个window的导数是非常稀疏的 ：<img src=" http:="" img.blog.csdn.net="" 20150702203923235"="" alt="这里写图片描述">"></a>但是还有一个问题，在每一个window中最多含有（2c-1）个单词（即vector，一个单词对应一个vector），所以得到的cost对每个window的导数是非常稀疏的 ：<img src="http://img.blog.csdn.net/20150702203923235" alt="这里写图片描述"></h4><h3 id="u7A00_u758F_u7684_u89E3_u51B3_u65B9_u6848_uFF1A1-_u4FDD_u6301_u5468_u56F4word_vectors_u7684_u6563_u5217_u503C_u30022-_u66F4_u65B0_u6574_u4E2Aword_embedding_matrix_L_u548CL_u2019_u7684_u786E_u5B9A_u7684_u67D0_u4E9B_u5217_u3002"><a href="#u7A00_u758F_u7684_u89E3_u51B3_u65B9_u6848_uFF1A1-_u4FDD_u6301_u5468_u56F4word_vectors_u7684_u6563_u5217_u503C_u30022-_u66F4_u65B0_u6574_u4E2Aword_embedding_matrix_L_u548CL_u2019_u7684_u786E_u5B9A_u7684_u67D0_u4E9B_u5217_u3002" class="headerlink" title="稀疏的解决方案：1.保持周围word vectors的散列值。2.更新整个word embedding matrix L和L’的确定的某些列。"></a>稀疏的解决方案：1.保持周围word vectors的散列值。2.更新整个word embedding matrix L和L’的确定的某些列。</h3><p><img src="http://img.blog.csdn.net/20150702205159073" alt="这里写图片描述"></p>
<h3 id="PSet1"><a href="#PSet1" class="headerlink" title="<strong>PSet1</strong>"></a><strong>PSet1</strong></h3><p><img src="http://img.blog.csdn.net/20150702205643947" alt="这里写图片描述"></p>
<h4 id="u4E3B_u8981_u601D_u60F3_uFF1A_u7528_u4E8C_u5206_u7C7B_u7684_u903B_u8F91_u56DE_u5F52_uFF0C_u8BAD_u7EC3_u4E00_u7EC4true_pairs_uFF08_u4E2D_u5FC3_u8BCD_u548C_u5176context_window_u5185_u7684_u5176_u4ED6_u8BCD_uFF09_u548C_u591A_u7EC4random_pairs_uFF08_u4E2D_u5FC3_u8BCD_u548C_u5176_u4ED6_u968F_u673A_u6311_u9009_u7684_u8BCD_uFF09"><a href="#u4E3B_u8981_u601D_u60F3_uFF1A_u7528_u4E8C_u5206_u7C7B_u7684_u903B_u8F91_u56DE_u5F52_uFF0C_u8BAD_u7EC3_u4E00_u7EC4true_pairs_uFF08_u4E2D_u5FC3_u8BCD_u548C_u5176context_window_u5185_u7684_u5176_u4ED6_u8BCD_uFF09_u548C_u591A_u7EC4random_pairs_uFF08_u4E2D_u5FC3_u8BCD_u548C_u5176_u4ED6_u968F_u673A_u6311_u9009_u7684_u8BCD_uFF09" class="headerlink" title="主要思想：用二分类的逻辑回归，训练一组true pairs（中心词和其context window内的其他词）和多组random pairs（中心词和其他随机挑选的词）"></a>主要思想：用二分类的逻辑回归，训练一组true pairs（中心词和其context window内的其他词）和多组random pairs（中心词和其他随机挑选的词）</h4><h4 id="skip-gram_u6A21_u578B_u548C_u8D1F_u91C7_u6837_uFF08k_u4E3A_u8D1F_u91C7_u6837_u6570_uFF09_uFF1A"><a href="#skip-gram_u6A21_u578B_u548C_u8D1F_u91C7_u6837_uFF08k_u4E3A_u8D1F_u91C7_u6837_u6570_uFF09_uFF1A" class="headerlink" title="skip-gram模型和负采样（k为负采样数）："></a>skip-gram模型和负采样（k为负采样数）：</h4><h4 id="skip-gram_cost_uFF08maximize_u8BE5_u51FD_u6570_uFF09"><a href="#skip-gram_cost_uFF08maximize_u8BE5_u51FD_u6570_uFF09" class="headerlink" title="skip-gram cost（maximize该函数）"></a>skip-gram cost（maximize该函数）</h4><p><img src="http://img.blog.csdn.net/20150702210538737" alt="这里写图片描述"></p>
<h4 id="u6216_u8005_u5199_u6210_uFF08_unigram_distribution_U_28w_29_uFF09_uFF1A"><a href="#u6216_u8005_u5199_u6210_uFF08_unigram_distribution_U_28w_29_uFF09_uFF1A" class="headerlink" title="或者写成（ unigram   distribution   U(w)）："></a>或者写成（ unigram   distribution   U(w)）：</h4><p><img src="http://img.blog.csdn.net/20150702210800811" alt="这里写图片描述"><br><img src="http://img.blog.csdn.net/20150702211321857" alt="这里写图片描述"></p>
<h4 id="u4F7F_u5F97_u4E0D_u9891_u7E41_u51FA_u73B0_u7684_u8BCD_u66F4_u591A_u7684_u88AB_u53D6_u6837"><a href="#u4F7F_u5F97_u4E0D_u9891_u7E41_u51FA_u73B0_u7684_u8BCD_u66F4_u591A_u7684_u88AB_u53D6_u6837" class="headerlink" title="使得不频繁出现的词更多的被取样"></a>使得不频繁出现的词更多的被取样</h4><h4 id="u53E6_u4E00_u4E2A_u6A21_u578B_uFF1ACBOW_uFF08continuous_bag_of_word_uFF09_uFF1A"><a href="#u53E6_u4E00_u4E2A_u6A21_u578B_uFF1ACBOW_uFF08continuous_bag_of_word_uFF09_uFF1A" class="headerlink" title="另一个模型：CBOW（continuous bag of word）："></a>另一个模型：CBOW（continuous bag of word）：</h4><h4 id="CBOW_u4E3B_u8981_u601D_u60F3_uFF1A_u901A_u8FC7_u5468_u56F4_u5355_u8BCD_u7684word_vectors_u7684_u548C_u9884_u6D4B_u4E2D_u5FC3_u8BCD_uFF0C_u4E0D_u540C_u4E8Eskip-gram_uFF0Cskip-gram_u662F_u901A_u8FC7_u4E2D_u5FC3_u8BCD_u9884_u6D4B_u5468_u56F4_u7684_u5355_u8BCDword_vectors_u3002"><a href="#CBOW_u4E3B_u8981_u601D_u60F3_uFF1A_u901A_u8FC7_u5468_u56F4_u5355_u8BCD_u7684word_vectors_u7684_u548C_u9884_u6D4B_u4E2D_u5FC3_u8BCD_uFF0C_u4E0D_u540C_u4E8Eskip-gram_uFF0Cskip-gram_u662F_u901A_u8FC7_u4E2D_u5FC3_u8BCD_u9884_u6D4B_u5468_u56F4_u7684_u5355_u8BCDword_vectors_u3002" class="headerlink" title="CBOW主要思想：通过周围单词的word vectors的和预测中心词，不同于skip-gram，skip-gram是通过中心词预测周围的单词word vectors。"></a>CBOW主要思想：通过周围单词的word vectors的和预测中心词，不同于skip-gram，skip-gram是通过中心词预测周围的单词word vectors。</h4><h4 id="u5355_u4E2A_u6A21_u578B_u8BAD_u7EC3_u540E_u4F1A_u83B7_u5F97L_u548CL_u2019_u4E24_u4E2A_u7531word_vectors_u7EC4_u6210_u7684_u77E9_u9635_uFF0C_u4F46_u662F_u8FD9_u4E24_u4E2A_u77E9_u9635_u6355_u83B7_u7684_u4FE1_u606F_u662F_u76F8_u4F3C_u7684_uFF0C_u6240_u4EE5_uFF0C_u6700_u597D_u7684_u4FE1_u606F_u7684_u662F_u5C06_u4ED6_u4EEC_u76F8_u52A0_uFF1A"><a href="#u5355_u4E2A_u6A21_u578B_u8BAD_u7EC3_u540E_u4F1A_u83B7_u5F97L_u548CL_u2019_u4E24_u4E2A_u7531word_vectors_u7EC4_u6210_u7684_u77E9_u9635_uFF0C_u4F46_u662F_u8FD9_u4E24_u4E2A_u77E9_u9635_u6355_u83B7_u7684_u4FE1_u606F_u662F_u76F8_u4F3C_u7684_uFF0C_u6240_u4EE5_uFF0C_u6700_u597D_u7684_u4FE1_u606F_u7684_u662F_u5C06_u4ED6_u4EEC_u76F8_u52A0_uFF1A" class="headerlink" title="单个模型训练后会获得L和L’两个由word vectors组成的矩阵，但是这两个矩阵捕获的信息是相似的，所以，最好的信息的是将他们相加："></a>单个模型训练后会获得L和L’两个由word vectors组成的矩阵，但是这两个矩阵捕获的信息是相似的，所以，最好的信息的是将他们相加：</h4><p><img src="http://img.blog.csdn.net/20150703130237307" alt="这里写图片描述"></p>
<h3 id="u5982_u4F55_u8BC4_u4F30word_vectors"><a href="#u5982_u4F55_u8BC4_u4F30word_vectors" class="headerlink" title="<strong>如何评估word vectors</strong>"></a><strong>如何评估word vectors</strong></h3><h3 id="word_vector_anology_3A"><a href="#word_vector_anology_3A" class="headerlink" title="word vector anology:"></a>word vector anology:</h3><h4 id="u5927_u591A_u6570_u4EE5_u524D_u8BC4_u4EF7word_vector_u7684_u65B9_u6CD5_u662F_u6BD4_u8F83_u76F8_u8FD1_u5355_u8BCD_u5BF9_u5E94_u7684vector_u95F4_u7684_u8DDD_u79BB_u548C_u89D2_u5EA6_uFF1A"><a href="#u5927_u591A_u6570_u4EE5_u524D_u8BC4_u4EF7word_vector_u7684_u65B9_u6CD5_u662F_u6BD4_u8F83_u76F8_u8FD1_u5355_u8BCD_u5BF9_u5E94_u7684vector_u95F4_u7684_u8DDD_u79BB_u548C_u89D2_u5EA6_uFF1A" class="headerlink" title="大多数以前评价word vector的方法是比较相近单词对应的vector间的距离和角度："></a>大多数以前评价word vector的方法是比较相近单词对应的vector间的距离和角度：</h4><p><img src="http://img.blog.csdn.net/20150703131502545" alt="这里写图片描述"></p>
<h4 id="milolov_u63D0_u51FA_u4E86_u57FA_u4E8Eword_anology_u7684_u591A_u7EF4_u8BC4_u4EF7_u65B9_u6CD5_uFF0C_u4F8B_u5982_uFF1A"><a href="#milolov_u63D0_u51FA_u4E86_u57FA_u4E8Eword_anology_u7684_u591A_u7EF4_u8BC4_u4EF7_u65B9_u6CD5_uFF0C_u4F8B_u5982_uFF1A" class="headerlink" title="milolov提出了基于word anology的多维评价方法，例如："></a>milolov提出了基于word anology的多维评价方法，例如：</h4><h4 id="u5BF9_u4E8E_u53E5_u5B50_u201Cking_is_to_queen_as_man_is_to_women_u201D_uFF0C_u76F8_u5BF9_u5E94_u7684word_vector_u5E94_u8BE5_u6EE1_u8DB3_uFF1Aking_-_queen__3D_man_-_women_u3002_u53C8_u6BD4_u5982_uFF0C_u5728G_loVe_u7684_u8BEF_u5DEE_u6D4B_u8BD5test_u4E2D_uFF08_u9884_u6D4B_u4E0B_u5212_u7EBF_u4E2D_u7684_u8BCD_uFF09_uFF1A"><a href="#u5BF9_u4E8E_u53E5_u5B50_u201Cking_is_to_queen_as_man_is_to_women_u201D_uFF0C_u76F8_u5BF9_u5E94_u7684word_vector_u5E94_u8BE5_u6EE1_u8DB3_uFF1Aking_-_queen__3D_man_-_women_u3002_u53C8_u6BD4_u5982_uFF0C_u5728G_loVe_u7684_u8BEF_u5DEE_u6D4B_u8BD5test_u4E2D_uFF08_u9884_u6D4B_u4E0B_u5212_u7EBF_u4E2D_u7684_u8BCD_uFF09_uFF1A" class="headerlink" title="对于句子“king is to queen as man is to women”，相对应的word vector应该满足：king - queen = man - women。又比如，在G loVe的误差测试test中（预测下划线中的词）："></a>对于句子“king is to queen as man is to women”，相对应的word vector应该满足：king - queen = man - women。又比如，在G loVe的误差测试test中（预测下划线中的词）：</h4><h4 id="1-_u5BF9_u4E8E_u8BED_u4E49semantic_uFF1AAthens_is_to_Greece_as_Berlin_is_to____3F"><a href="#1-_u5BF9_u4E8E_u8BED_u4E49semantic_uFF1AAthens_is_to_Greece_as_Berlin_is_to____3F" class="headerlink" title="1.对于语义semantic：Athens is to Greece as Berlin is to __?"></a>1.对于语义semantic：Athens is to Greece as Berlin is to __?</h4><h4 id="2-_u5BF9_u4E8E_u8BED_u6CD5syntactic_uFF1Adance_is_to_dancing_as_fly_is_to____3F"><a href="#2-_u5BF9_u4E8E_u8BED_u6CD5syntactic_uFF1Adance_is_to_dancing_as_fly_is_to____3F" class="headerlink" title="2.对于语法syntactic：dance is to dancing as fly is to __?"></a>2.对于语法syntactic：dance is to dancing as fly is to __?</h4><h3 id="Analogy_u8BC4_u4F30_u548C_u6A21_u578B_u53C2_u6570_u9009_u62E9"><a href="#Analogy_u8BC4_u4F30_u548C_u6A21_u578B_u53C2_u6570_u9009_u62E9" class="headerlink" title="<strong>Analogy评估和模型参数选择</strong>"></a><strong>Analogy评估和模型参数选择</strong></h3><h4 id="u5404_u4E2A_u6A21_u578B_u6D4B_u8BD5_u7ED3_u679C_uFF1A"><a href="#u5404_u4E2A_u6A21_u578B_u6D4B_u8BD5_u7ED3_u679C_uFF1A" class="headerlink" title="各个模型测试结果："></a>各个模型测试结果：</h4><p><img src="http://img.blog.csdn.net/20150703132558808" alt="这里写图片描述"></p>
<h4 id="u6A21_u578B_u53C2_u6570_u7684_u9009_u62E9_uFF1A"><a href="#u6A21_u578B_u53C2_u6570_u7684_u9009_u62E9_uFF1A" class="headerlink" title="模型参数的选择："></a>模型参数的选择：</h4><p><img src="http://img.blog.csdn.net/20150703132728700" alt="这里写图片描述"><br>对于GloVe来说，context window size设置为8，word vector的维数设置为300是个不错的选择。</p>
<h4 id="u4ECE_u6A21_u578B_u7684_u5176_u4ED6_u6D4B_u8BD5_u7ED3_u679C_u6765_u770B_uFF0C_u8FD8_u53EF_u4EE5_u5F97_u5230_u53E6_u5916_u4E00_u4E9B_u6709_u7528_u7684_u6280_u5DE7_uFF08_u7ED3_u8BBA_uFF09_uFF0C_u9488_u5BF9GloVe_uFF1A"><a href="#u4ECE_u6A21_u578B_u7684_u5176_u4ED6_u6D4B_u8BD5_u7ED3_u679C_u6765_u770B_uFF0C_u8FD8_u53EF_u4EE5_u5F97_u5230_u53E6_u5916_u4E00_u4E9B_u6709_u7528_u7684_u6280_u5DE7_uFF08_u7ED3_u8BBA_uFF09_uFF0C_u9488_u5BF9GloVe_uFF1A" class="headerlink" title="从模型的其他测试结果来看，还可以得到另外一些有用的技巧（结论），针对GloVe："></a>从模型的其他测试结果来看，还可以得到另外一些有用的技巧（结论），针对GloVe：</h4><h5 id="1-_u5BF9_u4E8E_u8BED_u6CD5syntactic_uFF1A_u8F83_u5C0F_u7684_u5355_u8FB9context_window_u4F1A_u7684_u5230_u66F4_u597D_u7684_u7ED3_u679C_uFF08_u539F_u56E0_u662Fsyntactic_u4E3B_u8981_u5728_u4E8E_u8BCD_u5E8F_uFF09"><a href="#1-_u5BF9_u4E8E_u8BED_u6CD5syntactic_uFF1A_u8F83_u5C0F_u7684_u5355_u8FB9context_window_u4F1A_u7684_u5230_u66F4_u597D_u7684_u7ED3_u679C_uFF08_u539F_u56E0_u662Fsyntactic_u4E3B_u8981_u5728_u4E8E_u8BCD_u5E8F_uFF09" class="headerlink" title="1.对于语法syntactic：较小的单边context window会的到更好的结果（原因是syntactic主要在于词序）"></a>1.对于语法syntactic：较小的单边context window会的到更好的结果（原因是syntactic主要在于词序）</h5><h5 id="2-_u5BF9_u4E8E_u8BED_u4E49semantic_uFF1A_u8F83_u5927_u7684_u53CC_u8FB9context_window_u4F1A_u5F97_u5230_u8F83_u597D_u7684_u7ED3_u679C"><a href="#2-_u5BF9_u4E8E_u8BED_u4E49semantic_uFF1A_u8F83_u5927_u7684_u53CC_u8FB9context_window_u4F1A_u5F97_u5230_u8F83_u597D_u7684_u7ED3_u679C" class="headerlink" title="2.对于语义semantic：较大的双边context window会得到较好的结果"></a>2.对于语义semantic：较大的双边context window会得到较好的结果</h5><h5 id="3-_u5BF9_u4E8E_u6570_u636E_u96C6corpus_u7684_u5927_u5C0F_uFF1A_u8D8A_u5927_u7684_u6570_u636E_u53CA_u4F1A_u6709_u66F4_u597D_u7684_u7ED3_u679C_uFF0C_u4F46_u662Fsemantic_u5BF9_u6570_u636E_u96C6_u7684_u5927_u5C0F_u5173_u7CFB_u4E0D_u90A3_u4E48_u660E_u663E_uFF0C_u800C_u662F_u548C_u6570_u636E_u96C6_u7684_u771F_u5B9E_u6027_u548C_u4E30_u5BCC_u5EA6_u6709_u5173_uFF08_u6240_u6709_u5728wikipedia_u4E0A_u8BAD_u7EC3_u5F97_u5230_u7684_u7ED3_u679C_u8981_u6BD4_u5176_u4ED6_u56FA_u5B9A_u4E0D_u53D8_u7684_u6570_u636E_u96C6_u7684_u7ED3_u679C_u8981_u597D_uFF09"><a href="#3-_u5BF9_u4E8E_u6570_u636E_u96C6corpus_u7684_u5927_u5C0F_uFF1A_u8D8A_u5927_u7684_u6570_u636E_u53CA_u4F1A_u6709_u66F4_u597D_u7684_u7ED3_u679C_uFF0C_u4F46_u662Fsemantic_u5BF9_u6570_u636E_u96C6_u7684_u5927_u5C0F_u5173_u7CFB_u4E0D_u90A3_u4E48_u660E_u663E_uFF0C_u800C_u662F_u548C_u6570_u636E_u96C6_u7684_u771F_u5B9E_u6027_u548C_u4E30_u5BCC_u5EA6_u6709_u5173_uFF08_u6240_u6709_u5728wikipedia_u4E0A_u8BAD_u7EC3_u5F97_u5230_u7684_u7ED3_u679C_u8981_u6BD4_u5176_u4ED6_u56FA_u5B9A_u4E0D_u53D8_u7684_u6570_u636E_u96C6_u7684_u7ED3_u679C_u8981_u597D_uFF09" class="headerlink" title="3.对于数据集corpus的大小：越大的数据及会有更好的结果，但是semantic对数据集的大小关系不那么明显，而是和数据集的真实性和丰富度有关（所有在wikipedia上训练得到的结果要比其他固定不变的数据集的结果要好）"></a>3.对于数据集corpus的大小：越大的数据及会有更好的结果，但是semantic对数据集的大小关系不那么明显，而是和数据集的真实性和丰富度有关（所有在wikipedia上训练得到的结果要比其他固定不变的数据集的结果要好）</h5><h4 id="u53EF_u80FD_u4F60_u4F1A_u60F3_u8981_u4E00_u4E2A_u8BCD_u7684word_vector_u6355_u83B7_u6240_u6709_u7C7B_u578B_u7684_u4FE1_u606F_uFF0C_u4F8B_u5982_uFF1Arun_u65E2_u662F_u52A8_u8BCD_u4E5F_u662F_u540D_u8BCD_u3002_u4F46_u662F_u5B9E_u9645_u4E0A_u5BF9_u4E8E_u4E0D_u540C_u7684_u8BCD_u6027_uFF0C_u5BF9_u5E94_u7684word_vector_u88AB_u62C9_u5411_u4E86_u4E0D_u540C_u7684_u65B9_u5411_uFF0C_u53C2_u8003_uFF1A_Improving_Word_Representa4ons_Via_Global_Context_And_Mul4ple_Word_Prototypes__28Huang_et-al-_2012_29_u3002"><a href="#u53EF_u80FD_u4F60_u4F1A_u60F3_u8981_u4E00_u4E2A_u8BCD_u7684word_vector_u6355_u83B7_u6240_u6709_u7C7B_u578B_u7684_u4FE1_u606F_uFF0C_u4F8B_u5982_uFF1Arun_u65E2_u662F_u52A8_u8BCD_u4E5F_u662F_u540D_u8BCD_u3002_u4F46_u662F_u5B9E_u9645_u4E0A_u5BF9_u4E8E_u4E0D_u540C_u7684_u8BCD_u6027_uFF0C_u5BF9_u5E94_u7684word_vector_u88AB_u62C9_u5411_u4E86_u4E0D_u540C_u7684_u65B9_u5411_uFF0C_u53C2_u8003_uFF1A_Improving_Word_Representa4ons_Via_Global_Context_And_Mul4ple_Word_Prototypes__28Huang_et-al-_2012_29_u3002" class="headerlink" title="可能你会想要一个词的word vector捕获所有类型的信息，例如：run既是动词也是名词。但是实际上对于不同的词性，对应的word vector被拉向了不同的方向，参考：  Improving  Word    Representa4ons  Via  Global Context And Mul4ple Word     Prototypes (Huang  et.al.  2012)。"></a>可能你会想要一个词的word vector捕获所有类型的信息，例如：run既是动词也是名词。但是实际上对于不同的词性，对应的word vector被拉向了不同的方向，参考：  Improving  Word    Representa4ons  Via  Global Context And Mul4ple Word     Prototypes (Huang  et.al.  2012)。</h4><p><img src="http://img.blog.csdn.net/20150703134702552" alt="这里写图片描述"><img src="http://img.blog.csdn.net/20150703134745343" alt="这里写图片描述"></p>
<h4 id="u597D_u7684word_vector_u7684_u4E00_u4E2A_u5B9E_u4F8B_uFF0Cnamed_entity_recognition_uFF08_u547D_u540D_u5B9E_u4F53_u8BC6_u522B_uFF09_uFF1A_u6807_u8BB0_u4E00_u6BB5_u6587_u5B57_u4E2D_u7684_u4E00_u7CFB_u5217_u540D_u8BCD_uFF0C_u5982_u516C_u53F8_u540D_uFF0C_u5730_u5740_u540D_uFF0C_u4EBA_u540D_u7B49_u3002"><a href="#u597D_u7684word_vector_u7684_u4E00_u4E2A_u5B9E_u4F8B_uFF0Cnamed_entity_recognition_uFF08_u547D_u540D_u5B9E_u4F53_u8BC6_u522B_uFF09_uFF1A_u6807_u8BB0_u4E00_u6BB5_u6587_u5B57_u4E2D_u7684_u4E00_u7CFB_u5217_u540D_u8BCD_uFF0C_u5982_u516C_u53F8_u540D_uFF0C_u5730_u5740_u540D_uFF0C_u4EBA_u540D_u7B49_u3002" class="headerlink" title="好的word vector的一个实例，named entity recognition（命名实体识别）：标记一段文字中的一系列名词，如公司名，地址名，人名等。"></a>好的word vector的一个实例，named entity recognition（命名实体识别）：标记一段文字中的一系列名词，如公司名，地址名，人名等。</h4><h3 id="u5728_u795E_u7ECF_u7F51_u7EDC_u4E2D_u4F7F_u7528word_vector_uFF08_u5355_u4E2A_u8BCD_uFF0C_u65E0context_window_uFF09"><a href="#u5728_u795E_u7ECF_u7F51_u7EDC_u4E2D_u4F7F_u7528word_vector_uFF08_u5355_u4E2A_u8BCD_uFF0C_u65E0context_window_uFF09" class="headerlink" title="<strong>在神经网络中使用word vector（单个词，无context window）</strong>"></a><strong>在神经网络中使用word vector（单个词，无context window）</strong></h3><h4 id="deep_learned_word_vector_u7684_u4E3B_u8981_u597D_u5904_uFF1A"><a href="#deep_learned_word_vector_u7684_u4E3B_u8981_u597D_u5904_uFF1A" class="headerlink" title="<strong>deep learned word vector的主要好处：</strong>"></a><strong>deep learned word vector的主要好处：</strong></h4><h5 id="1-_u6B63_u786E_u5BF9_u5355_u8BCD_u5206_u7C7B_u7684_u80FD_u529B_uFF0C_u4F8B_u5982_uFF1Acountries_u7C7B_u7684word_vectors_u805A_u96C6_u5728_u4E00_u8D77_uFF0C_u6709_u5229_u4E8E_u5BF9_u5730_u5740_u8FDB_u884C_u5206_u7C7B_u3002"><a href="#1-_u6B63_u786E_u5BF9_u5355_u8BCD_u5206_u7C7B_u7684_u80FD_u529B_uFF0C_u4F8B_u5982_uFF1Acountries_u7C7B_u7684word_vectors_u805A_u96C6_u5728_u4E00_u8D77_uFF0C_u6709_u5229_u4E8E_u5BF9_u5730_u5740_u8FDB_u884C_u5206_u7C7B_u3002" class="headerlink" title="1.正确对单词分类的能力，例如：countries类的word vectors聚集在一起，有利于对地址进行分类。"></a>1.正确对单词分类的能力，例如：countries类的word vectors聚集在一起，有利于对地址进行分类。</h5><h5 id="2-_u6574_u5408_u5404_u7C7B_u4FE1_u606F_u5230word_vectors_uFF0C_u4F8B_u5982_uFF1A_u5C06_u60C5_u611F_u4FE1_u606F_u6620_u5C04_u5230word_vector_uFF0C_u6709_u5229_u4E8E_u627E_u5230_u6570_u636E_u96C6corpus_u4E2D_u7684_u4E00_u4E9B_u79EF_u6781_u7684_u83B7_u5F97_u6D88_u6781_u7684_u5355_u8BCD_u3002"><a href="#2-_u6574_u5408_u5404_u7C7B_u4FE1_u606F_u5230word_vectors_uFF0C_u4F8B_u5982_uFF1A_u5C06_u60C5_u611F_u4FE1_u606F_u6620_u5C04_u5230word_vector_uFF0C_u6709_u5229_u4E8E_u627E_u5230_u6570_u636E_u96C6corpus_u4E2D_u7684_u4E00_u4E9B_u79EF_u6781_u7684_u83B7_u5F97_u6D88_u6781_u7684_u5355_u8BCD_u3002" class="headerlink" title="2.整合各类信息到word vectors，例如：将情感信息映射到word vector，有利于找到数据集corpus中的一些积极的获得消极的单词。"></a>2.整合各类信息到word vectors，例如：将情感信息映射到word vector，有利于找到数据集corpus中的一些积极的获得消极的单词。</h5><h3 id="softmax_uFF1A"><a href="#softmax_uFF1A" class="headerlink" title="<strong>softmax</strong>："></a><strong>softmax</strong>：</h3><p><img src="http://img.blog.csdn.net/20150703142635158" alt="这里写图片描述"><br>通常用于类别数大于2的分类任务</p>
<h4 id="u76F8_u5173_u672F_u8BED_uFF1A_Loss_function__3D_cost_function__3D_objective_function"><a href="#u76F8_u5173_u672F_u8BED_uFF1A_Loss_function__3D_cost_function__3D_objective_function" class="headerlink" title="相关术语：  Loss    function    =   cost function   =   objective   function"></a>相关术语：  Loss    function    =   cost function   =   objective   function</h4><h4 id="softmax_u7684loss_u51FD_u6570_uFF1ACross_entropy_uFF08_u4EA4_u53C9_u71B5_uFF09"><a href="#softmax_u7684loss_u51FD_u6570_uFF1ACross_entropy_uFF08_u4EA4_u53C9_u71B5_uFF09" class="headerlink" title="softmax的loss函数：Cross entropy（交叉熵）"></a>softmax的loss函数：Cross entropy（交叉熵）</h4><h4 id="u8BA1_u7B97p_28y_7Cx_29_uFF1A"><a href="#u8BA1_u7B97p_28y_7Cx_29_uFF1A" class="headerlink" title="计算p(y|x)："></a>计算p(y|x)：</h4><h5 id="1-_u9996_u5148_u5C06_u6743_u91CDW_u7684_u7B2Cy_u884C_u4E0EX_uFF08_u8BAD_u7EC3_u96C6word_vector_uFF09_u7684_u6BCF_u4E00_u884C_uFF08_u5217_uFF09_u76F8_u4E58_uFF08_u89C6_u5177_u4F53_u7684_u77E9_u9635_u6709_u533A_u522B_uFF09_uFF1A"><a href="#1-_u9996_u5148_u5C06_u6743_u91CDW_u7684_u7B2Cy_u884C_u4E0EX_uFF08_u8BAD_u7EC3_u96C6word_vector_uFF09_u7684_u6BCF_u4E00_u884C_uFF08_u5217_uFF09_u76F8_u4E58_uFF08_u89C6_u5177_u4F53_u7684_u77E9_u9635_u6709_u533A_u522B_uFF09_uFF1A" class="headerlink" title="1.首先将权重W的第y行与X（训练集word vector）的每一行（列）相乘（视具体的矩阵有区别）："></a>1.首先将权重W的第y行与X（训练集word vector）的每一行（列）相乘（视具体的矩阵有区别）：</h5><p><img src="http://img.blog.csdn.net/20150703143833135" alt="这里写图片描述"></p>
<h5 id="2-_u9010_u4E00_u76F8_u4E58_uFF0C_u8BA1_u7B97fc_for_c_3D1_2C_u2026_2CC"><a href="#2-_u9010_u4E00_u76F8_u4E58_uFF0C_u8BA1_u7B97fc_for_c_3D1_2C_u2026_2CC" class="headerlink" title="2.逐一相乘，计算fc   for c=1,…,C"></a>2.逐一相乘，计算fc   for c=1,…,C</h5><h5 id="3-_u5F52_u4E00_u5316_uFF08_u5C06_u6570_u503C_u9650_u5236_u57280_uFF5E1_u4E4B_u95F4_uFF09_uFF0C_u901A_u8FC7softmax_u83B7_u5F97_u6982_u7387_u503C_uFF1A"><a href="#3-_u5F52_u4E00_u5316_uFF08_u5C06_u6570_u503C_u9650_u5236_u57280_uFF5E1_u4E4B_u95F4_uFF09_uFF0C_u901A_u8FC7softmax_u83B7_u5F97_u6982_u7387_u503C_uFF1A" class="headerlink" title="3.归一化（将数值限制在0～1之间），通过softmax获得概率值："></a>3.归一化（将数值限制在0～1之间），通过softmax获得概率值：</h5><p><img src="http://img.blog.csdn.net/20150703144348435" alt="这里写图片描述"></p>
<h4 id="u6700_u5C0F_u5316_u8D1Flog_u4F3C_u7136_u51FD_u6570_uFF08_u5BF9_u4E8E_u591A_u5206_u7C7B_u95EE_u9898_uFF0C_u5C06_u6240_u6709_u7C7B_u522B_u7684_u4EA4_u53C9_u71B5_u52A0_u8D77_u6765_uFF0C_u4F5C_u4E3A_u6700_u540E_u7684loss_u65B9_u7A0B_uFF09_uFF1A"><a href="#u6700_u5C0F_u5316_u8D1Flog_u4F3C_u7136_u51FD_u6570_uFF08_u5BF9_u4E8E_u591A_u5206_u7C7B_u95EE_u9898_uFF0C_u5C06_u6240_u6709_u7C7B_u522B_u7684_u4EA4_u53C9_u71B5_u52A0_u8D77_u6765_uFF0C_u4F5C_u4E3A_u6700_u540E_u7684loss_u65B9_u7A0B_uFF09_uFF1A" class="headerlink" title="最小化负log似然函数（对于多分类问题，将所有类别的交叉熵加起来，作为最后的loss方程）："></a>最小化负log似然函数（对于多分类问题，将所有类别的交叉熵加起来，作为最后的loss方程）：</h4><p><img src="http://img.blog.csdn.net/20150703151327383" alt="这里写图片描述"></p>
<h4 id="u8BAD_u7EC3_u65F6_uFF0C_u4F7F_u7528ground_truth_uFF1A_u5BF9_u4E8E_u6B63_u786E_u7684_u7C7B_u522B_u7F6E1_uFF0C_u5176_u4F59_u7684_u7F6E0_uFF0C_u5373"><a href="#u8BAD_u7EC3_u65F6_uFF0C_u4F7F_u7528ground_truth_uFF1A_u5BF9_u4E8E_u6B63_u786E_u7684_u7C7B_u522B_u7F6E1_uFF0C_u5176_u4F59_u7684_u7F6E0_uFF0C_u5373" class="headerlink" title="训练时，使用ground truth：对于正确的类别置1，其余的置0，即"></a>训练时，使用ground truth：对于正确的类别置1，其余的置0，即</h4><h4 id="p_3D_5B0_2C_u2026_2C0_2C1_2C0_2C_u20260_5D_uFF0C_u6240_u4EE5_u4EA4_u53C9_u71B5_u53EA_u8BA1_u7B97_u6BCF_u4E2A_u6837_u672C_u7684right_class_u6240_u5BF9_u5E94_u7684_u8BEF_u5DEE_uFF0C_u9519_u8BEF_u7C7B_u522B_u4E5F_u5BF9_u6C42_u68AF_u5EA6_u65E0_u5F71_u54CD_uFF08q_u4E3Asoftmax_uFF09_uFF1A"><a href="#p_3D_5B0_2C_u2026_2C0_2C1_2C0_2C_u20260_5D_uFF0C_u6240_u4EE5_u4EA4_u53C9_u71B5_u53EA_u8BA1_u7B97_u6BCF_u4E2A_u6837_u672C_u7684right_class_u6240_u5BF9_u5E94_u7684_u8BEF_u5DEE_uFF0C_u9519_u8BEF_u7C7B_u522B_u4E5F_u5BF9_u6C42_u68AF_u5EA6_u65E0_u5F71_u54CD_uFF08q_u4E3Asoftmax_uFF09_uFF1A" class="headerlink" title="p=[0,…,0,1,0,…0]，所以交叉熵只计算每个样本的right class所对应的误差，错误类别也对求梯度无影响（q为softmax）："></a>p=[0,…,0,1,0,…0]，所以交叉熵只计算每个样本的right class所对应的误差，错误类别也对求梯度无影响（q为softmax）：</h4><p><img src="http://img.blog.csdn.net/20150703162955748" alt="这里写图片描述"></p>
<h4 id="u4E5F_u53EF_u4EE5_u5199_u6210_uFF1A"><a href="#u4E5F_u53EF_u4EE5_u5199_u6210_uFF1A" class="headerlink" title="也可以写成："></a>也可以写成：</h4><p><img src="http://img.blog.csdn.net/20150703163057570" alt="这里写图片描述"></p>
<h4 id="u6240_u4EE5_u6700_u5C0F_u5316_u4EA4_u53C9_u71B5_u53D8_u6210_u4E86_u6700_u5C0F_u5316KL_divergence_uFF08KL__u6563_u5EA6_uFF09_uFF0CKL_u6563_u5EA6_u5E76_u975E_u8868_u793A_u8DDD_u79BB_uFF0C_u800C_u662F_u6D4B_u91CF_u4E24_u4E2A_u6982_u7387_u5206_u5E03_uFF08p_u548Cq_uFF09_u4E4B_u95F4_u7684_u5DEE_u5F02_uFF1A"><a href="#u6240_u4EE5_u6700_u5C0F_u5316_u4EA4_u53C9_u71B5_u53D8_u6210_u4E86_u6700_u5C0F_u5316KL_divergence_uFF08KL__u6563_u5EA6_uFF09_uFF0CKL_u6563_u5EA6_u5E76_u975E_u8868_u793A_u8DDD_u79BB_uFF0C_u800C_u662F_u6D4B_u91CF_u4E24_u4E2A_u6982_u7387_u5206_u5E03_uFF08p_u548Cq_uFF09_u4E4B_u95F4_u7684_u5DEE_u5F02_uFF1A" class="headerlink" title="所以最小化交叉熵变成了最小化KL divergence（KL 散度），KL散度并非表示距离，而是测量两个概率分布（p和q）之间的差异："></a>所以最小化交叉熵变成了最小化KL divergence（KL 散度），KL散度并非表示距离，而是测量两个概率分布（p和q）之间的差异：</h4><p><img src="http://img.blog.csdn.net/20150703164036144" alt="这里写图片描述"></p>
<h4 id="u5C06_u4EA4_u53C9_u71B5_u5206_u522B_u5BF9X_u548CW_u6C42_u5BFC_uFF08_u89C1_u89C6_u9891_uFF09"><a href="#u5C06_u4EA4_u53C9_u71B5_u5206_u522B_u5BF9X_u548CW_u6C42_u5BFC_uFF08_u89C1_u89C6_u9891_uFF09" class="headerlink" title="将交叉熵分别对X和W求导（见视频）"></a>将交叉熵分别对X和W求导（见视频）</h4><h3 id="u5B9E_u4F8B_uFF1A_u60C5_u611F_u5206_u6790_uFF08_u5355_u4E2A_u8BCD_uFF0C_u65E0context_window_uFF09"><a href="#u5B9E_u4F8B_uFF1A_u60C5_u611F_u5206_u6790_uFF08_u5355_u4E2A_u8BCD_uFF0C_u65E0context_window_uFF09" class="headerlink" title="<strong>实例：情感分析（单个词，无context window）</strong>"></a><strong>实例：情感分析（单个词，无context window）</strong></h3><h4 id="u4E24_u4E2A_u8BAD_u7EC3_u65B9_u6848_uFF1A"><a href="#u4E24_u4E2A_u8BAD_u7EC3_u65B9_u6848_uFF1A" class="headerlink" title="两个训练方案："></a>两个训练方案：</h4><h5 id="1-_u56FA_u5B9Aword_vector_u7684_u503C_uFF0C_u53EA_u8BAD_u7EC3softmax_u7684_u6743_u503CW"><a href="#1-_u56FA_u5B9Aword_vector_u7684_u503C_uFF0C_u53EA_u8BAD_u7EC3softmax_u7684_u6743_u503CW" class="headerlink" title="1.固定word vector的值，只训练softmax的权值W"></a>1.固定word vector的值，只训练softmax的权值W</h5><h5 id="2-_u8BAD_u7EC3word_vector_u7684_u503C_uFF0C_u540C_u65F6_u4E5F_u8BAD_u7EC3softmax_u7684_u6743_u503CW"><a href="#2-_u8BAD_u7EC3word_vector_u7684_u503C_uFF0C_u540C_u65F6_u4E5F_u8BAD_u7EC3softmax_u7684_u6743_u503CW" class="headerlink" title="2.训练word vector的值，同时也训练softmax的权值W"></a>2.训练word vector的值，同时也训练softmax的权值W</h5><h4 id="u8BAD_u7EC3word_vector_u7684_u5229_u5F0A_uFF1A"><a href="#u8BAD_u7EC3word_vector_u7684_u5229_u5F0A_uFF1A" class="headerlink" title="训练word vector的利弊："></a>训练word vector的利弊：</h4><h5 id="1-_u66F4_u597D_u7684_u62DF_u5408_u8BAD_u7EC3_u96C6_uFF08training_set_uFF0C_u975Etest_set_uFF09"><a href="#1-_u66F4_u597D_u7684_u62DF_u5408_u8BAD_u7EC3_u96C6_uFF08training_set_uFF0C_u975Etest_set_uFF09" class="headerlink" title="1.更好的拟合训练集（training set，非test set）"></a>1.更好的拟合训练集（training set，非test set）</h5><h5 id="2-_u66F4_u5DEE_u7684_u6CDB_u5316_u7279_u6027_uFF08because_the_words_move_in_the_vector_space_uFF09"><a href="#2-_u66F4_u5DEE_u7684_u6CDB_u5316_u7279_u6027_uFF08because_the_words_move_in_the_vector_space_uFF09" class="headerlink" title="2.更差的泛化特性（because  the    words   move    in  the vector  space）"></a>2.更差的泛化特性（because  the    words   move    in  the vector  space）</h5><p><img src="http://img.blog.csdn.net/20150703165337050" alt="这里写图片描述"><br>可视化情感分析中，训练得到的word vector</p>
<h3 id="u4E0B_u4E00_u8282"><a href="#u4E0B_u4E00_u8282" class="headerlink" title="<strong>下一节</strong>"></a><strong>下一节</strong></h3><h4 id="u52A0_u4E0Acontext_window_uFF0C_u7ED9context_window_u6B63_u4E2D_u95F4_u7684_u8BCD_u5206_u7C7B"><a href="#u52A0_u4E0Acontext_window_uFF0C_u7ED9context_window_u6B63_u4E2D_u95F4_u7684_u8BCD_u5206_u7C7B" class="headerlink" title="加上context window，给context window正中间的词分类"></a>加上context window，给context window正中间的词分类</h4><h4 id="u77E5_u8BC6_u70B9_uFF1Asoftmax_uFF0C_u4EA4_u53C9_u71B5_u8BEF_u5DEE_uFF0Cmax-margin_loss"><a href="#u77E5_u8BC6_u70B9_uFF1Asoftmax_uFF0C_u4EA4_u53C9_u71B5_u8BEF_u5DEE_uFF0Cmax-margin_loss" class="headerlink" title="知识点：softmax，交叉熵误差，max-margin loss"></a>知识点：softmax，交叉熵误差，max-margin loss</h4>
            
          </span>
        
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2015/10/04/‎Summarize/cnn-for-visual-rcognition-stanford-2015-ef-bc-88-e4-ba-8c-ef-bc-89/" itemprop="url">
                  CNN for Visual Rcognition --- Stanford 2015 （二）
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            發表於
            <time itemprop="dateCreated" datetime="2015-10-04T19:38:26+08:00" content="2015-10-04">
              2015-10-04
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp; 分類於
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/Summarize/" itemprop="url" rel="index">
                    <span itemprop="name">Summarize</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

        </div>
      </header>
    


    <div class="post-body">

      
      

      
        
          <span itemprop="articleBody">
            
              <p>接着上一篇的内容：</p>
<h1 id="u56DB_uFF1ATransfer_Learning_uFF1A"><a href="#u56DB_uFF1ATransfer_Learning_uFF1A" class="headerlink" title="四：Transfer Learning："></a>四：Transfer Learning：</h1><p><img src="http://img.blog.csdn.net/20150811115636983" alt="这里写图片描述"></p>
<h3 id="1-_u5BF9_u4E8E_u6570_u636E_u91CF_u5C11_u6216_u8005_u4E2D_u7B49_u7684_u60C5_u51B5_uFF0C_u8FC1_u79FB_u5B66_u4E60_u5F88_u6709_u7528"><a href="#1-_u5BF9_u4E8E_u6570_u636E_u91CF_u5C11_u6216_u8005_u4E2D_u7B49_u7684_u60C5_u51B5_uFF0C_u8FC1_u79FB_u5B66_u4E60_u5F88_u6709_u7528" class="headerlink" title="1.对于数据量少或者中等的情况，迁移学习很有用"></a>1.对于数据量少或者中等的情况，迁移学习很有用</h3><h3 id="2-_u57FA_u4E8EImageNet_u7684_u5B9E_u9A8C_uFF0C_u5C06ImageNet_u7684_u6240_u6709_u7C7B_u7684_u5404_u5206_u4E00_u534A_u4E3AA_uFF0CB_uFF1A"><a href="#2-_u57FA_u4E8EImageNet_u7684_u5B9E_u9A8C_uFF0C_u5C06ImageNet_u7684_u6240_u6709_u7C7B_u7684_u5404_u5206_u4E00_u534A_u4E3AA_uFF0CB_uFF1A" class="headerlink" title="2.基于ImageNet的实验，将ImageNet的所有类的各分一半为A，B："></a>2.基于ImageNet的实验，将ImageNet的所有类的各分一半为A，B：</h3><h4 id="uFF081_uFF09-_u5148_u8BAD_u7EC3A_u90E8_u5206_uFF0C_u7136_u540E_u5C06_u524Dn_u5C42_u7684_u53C2_u6570_u4FDD_u5B58_u597D_uFF1B_u518D_u91CD_u65B0_u521D_u59CB_u5316_u540En+_u5C42_u7684_u53C2_u6570_uFF0C_u7528B_u90E8_u5206_u8BAD_u7EC3_uFF1B_u518D_u5C06_u524D_u9762_u4FDD_u5B58_u597D_u7684_u53C2_u6570_uFF0C_u548C_u540E_u9762_u8BAD_u7EC3B_u90E8_u5206_u5F97_u5230_u7684_u53C2_u6570_u7ED3_u5408_uFF0C_u5728B_u7684_u9A8C_u8BC1_u96C6_u4E0A_u8FDB_u884C_u9A8C_u8BC1_uFF1A"><a href="#uFF081_uFF09-_u5148_u8BAD_u7EC3A_u90E8_u5206_uFF0C_u7136_u540E_u5C06_u524Dn_u5C42_u7684_u53C2_u6570_u4FDD_u5B58_u597D_uFF1B_u518D_u91CD_u65B0_u521D_u59CB_u5316_u540En+_u5C42_u7684_u53C2_u6570_uFF0C_u7528B_u90E8_u5206_u8BAD_u7EC3_uFF1B_u518D_u5C06_u524D_u9762_u4FDD_u5B58_u597D_u7684_u53C2_u6570_uFF0C_u548C_u540E_u9762_u8BAD_u7EC3B_u90E8_u5206_u5F97_u5230_u7684_u53C2_u6570_u7ED3_u5408_uFF0C_u5728B_u7684_u9A8C_u8BC1_u96C6_u4E0A_u8FDB_u884C_u9A8C_u8BC1_uFF1A" class="headerlink" title="（1）.先训练A部分，然后将前n层的参数保存好；再重新初始化后n+层的参数，用B部分训练；再将前面保存好的参数，和后面训练B部分得到的参数结合，在B的验证集上进行验证："></a>（1）.先训练A部分，然后将前n层的参数保存好；再重新初始化后n+层的参数，用B部分训练；再将前面保存好的参数，和后面训练B部分得到的参数结合，在B的验证集上进行验证：</h4><p><img src="http://img.blog.csdn.net/20150811144835350" alt="这里写图片描述"></p>
<h4 id="uFF082_uFF09-_u5148_u8BAD_u7EC3A_u90E8_u5206_uFF0C_u8BAD_u7EC3_u5B8CA_u540E_u91CD_u65B0_u521D_u59CB_u5316n+_u5C42_u540E_u9762_u7684_u53C2_u6570_uFF0C_u518D_u5728B_u4E0A_u8FDB_u884C_u8BAD_u7EC3_uFF0C_u6700_u540E_u5728B_u7684_u9A8C_u8BC1_u96C6_u4E0A_u9A8C_u8BC1_uFF1A"><a href="#uFF082_uFF09-_u5148_u8BAD_u7EC3A_u90E8_u5206_uFF0C_u8BAD_u7EC3_u5B8CA_u540E_u91CD_u65B0_u521D_u59CB_u5316n+_u5C42_u540E_u9762_u7684_u53C2_u6570_uFF0C_u518D_u5728B_u4E0A_u8FDB_u884C_u8BAD_u7EC3_uFF0C_u6700_u540E_u5728B_u7684_u9A8C_u8BC1_u96C6_u4E0A_u9A8C_u8BC1_uFF1A" class="headerlink" title="（2）.先训练A部分，训练完A后重新初始化n+层后面的参数，再在B上进行训练，最后在B的验证集上验证："></a>（2）.先训练A部分，训练完A后重新初始化n+层后面的参数，再在B上进行训练，最后在B的验证集上验证：</h4><p><img src="http://img.blog.csdn.net/20150811144943791" alt="这里写图片描述"></p>
<h4 id="uFF083_uFF09-_u5148_u8BAD_u7EC3B_u90E8_u5206_uFF0C_u56FA_u5B9A_u5E76_u4FDD_u5B58_u524Dn_u5C42_u7684_u53C2_u6570_uFF1B_u518D_u91CD_u65B0_u521D_u59CB_u5316_u540En+_u5C42_u7684_u53C2_u6570_uFF0C_u518D_u6B21_u5728B_u4E0A_u8FDB_u884C_u8BAD_u7EC3_uFF1B_u6700_u540E_u5C06_u524D_u9762_u4FDD_u5B58_u597D_u7684_u524Dn_u5C42_u53C2_u6570_uFF0C_u4E0E_u91CD_u65B0_u8BAD_u7EC3B_u7684_u540En+_u5C42_u53C2_u6570_u7ED3_u5408_uFF0C_u5728B_u7684_u9A8C_u8BC1_u96C6_u4E0A_u9A8C_u8BC1_uFF1A"><a href="#uFF083_uFF09-_u5148_u8BAD_u7EC3B_u90E8_u5206_uFF0C_u56FA_u5B9A_u5E76_u4FDD_u5B58_u524Dn_u5C42_u7684_u53C2_u6570_uFF1B_u518D_u91CD_u65B0_u521D_u59CB_u5316_u540En+_u5C42_u7684_u53C2_u6570_uFF0C_u518D_u6B21_u5728B_u4E0A_u8FDB_u884C_u8BAD_u7EC3_uFF1B_u6700_u540E_u5C06_u524D_u9762_u4FDD_u5B58_u597D_u7684_u524Dn_u5C42_u53C2_u6570_uFF0C_u4E0E_u91CD_u65B0_u8BAD_u7EC3B_u7684_u540En+_u5C42_u53C2_u6570_u7ED3_u5408_uFF0C_u5728B_u7684_u9A8C_u8BC1_u96C6_u4E0A_u9A8C_u8BC1_uFF1A" class="headerlink" title="（3）.先训练B部分，固定并保存前n层的参数；再重新初始化后n+层的参数，再次在B上进行训练；最后将前面保存好的前n层参数，与重新训练B的后n+层参数结合，在B的验证集上验证："></a>（3）.先训练B部分，固定并保存前n层的参数；再重新初始化后n+层的参数，再次在B上进行训练；最后将前面保存好的前n层参数，与重新训练B的后n+层参数结合，在B的验证集上验证：</h4><p><img src="http://img.blog.csdn.net/20150811145436603" alt="这里写图片描述"></p>
<h4 id="uFF084_uFF09-_u5148_u8BAD_u7EC3B_u90E8_u5206_uFF0C_u518D_u91CD_u65B0_u521D_u59CB_u5316_u540En+_u5C42_u7684_u53C2_u6570_uFF1B_u518D_u6B21_u5728B_u4E0A_u91CD_u65B0_u8BAD_u7EC3_uFF1B_u6700_u540E_u5728B_u7684_u9A8C_u8BC1_u96C6_u4E0A_u9A8C_u8BC1_uFF1A"><a href="#uFF084_uFF09-_u5148_u8BAD_u7EC3B_u90E8_u5206_uFF0C_u518D_u91CD_u65B0_u521D_u59CB_u5316_u540En+_u5C42_u7684_u53C2_u6570_uFF1B_u518D_u6B21_u5728B_u4E0A_u91CD_u65B0_u8BAD_u7EC3_uFF1B_u6700_u540E_u5728B_u7684_u9A8C_u8BC1_u96C6_u4E0A_u9A8C_u8BC1_uFF1A" class="headerlink" title="（4）.先训练B部分，再重新初始化后n+层的参数；再次在B上重新训练；最后在B的验证集上验证："></a>（4）.先训练B部分，再重新初始化后n+层的参数；再次在B上重新训练；最后在B的验证集上验证：</h4><p><img src="http://img.blog.csdn.net/20150811145722383" alt="这里写图片描述"><br>３.总结一下上面的实验结果：<br><img src="http://img.blog.csdn.net/20150811145952894" alt="这里写图片描述"></p>
<h3 id="4-_u4E0B_u9762_u5E94_u8BE5_u662F_u674E_u98DE_u98DE_u8001_u5E08TED_u6F14_u8BB2_u5185_u5BB9_u7684_u539F_u7406_uFF1A"><a href="#4-_u4E0B_u9762_u5E94_u8BE5_u662F_u674E_u98DE_u98DE_u8001_u5E08TED_u6F14_u8BB2_u5185_u5BB9_u7684_u539F_u7406_uFF1A" class="headerlink" title="4.下面应该是李飞飞老师TED演讲内容的原理："></a>4.下面应该是李飞飞老师TED演讲内容的原理：</h3><p><img src="http://img.blog.csdn.net/20150811150858370" alt="这里写图片描述"></p>
<h3 id="5-_u5904_u7406_u5C0F_u6570_u636E_u96C6_u7684_u4E00_u4E9B_u5EFA_u8BAE_uFF1A"><a href="#5-_u5904_u7406_u5C0F_u6570_u636E_u96C6_u7684_u4E00_u4E9B_u5EFA_u8BAE_uFF1A" class="headerlink" title="5.处理小数据集的一些建议："></a>5.处理小数据集的一些建议：</h3><p><img src="http://img.blog.csdn.net/20150811151018345" alt="这里写图片描述"></p>
<h1 id="u4E94_uFF1ASqueezing_out_the_last_few_percent"><a href="#u4E94_uFF1ASqueezing_out_the_last_few_percent" class="headerlink" title="五：Squeezing out the last few percent"></a>五：Squeezing out the last few percent</h1><h3 id="1-_u4F7F_u7528_u5C0Fsize_u7684filter_u6BD4_u4F7F_u7528_u5927size_u7684filter_u7684_u6548_u679C_u8981_u597D_u5F97_u591A_uFF0C_u5C0Fsize_u7684filter_u80FD_u591F_u589E_u52A0non-linearities_u6570_uFF0C_u5E76_u4E14_u80FD_u51CF_u5C11_u9700_u8981_u8BAD_u7EC3_u7684_u53C2_u6570_uFF08_u8BD5_u60F3_u4E00_u4E2A7_7_u7684patch_uFF0C_u7528_u4E00_u4E2A7_7_u7684filter_u5377_u79EF_uFF0C_u548C_u7528_u4E09_u5C42_u76843*3_u7684filter_u5377_u79EF_uFF0C_u5F97_u5230_u7684_u7ED3_u679C_u90FD_u662F_u4E00_u4E2Ascalar_uFF09_u2014more_non-linearities_and_deeper_gives_better_results_uFF1A"><a href="#1-_u4F7F_u7528_u5C0Fsize_u7684filter_u6BD4_u4F7F_u7528_u5927size_u7684filter_u7684_u6548_u679C_u8981_u597D_u5F97_u591A_uFF0C_u5C0Fsize_u7684filter_u80FD_u591F_u589E_u52A0non-linearities_u6570_uFF0C_u5E76_u4E14_u80FD_u51CF_u5C11_u9700_u8981_u8BAD_u7EC3_u7684_u53C2_u6570_uFF08_u8BD5_u60F3_u4E00_u4E2A7_7_u7684patch_uFF0C_u7528_u4E00_u4E2A7_7_u7684filter_u5377_u79EF_uFF0C_u548C_u7528_u4E09_u5C42_u76843*3_u7684filter_u5377_u79EF_uFF0C_u5F97_u5230_u7684_u7ED3_u679C_u90FD_u662F_u4E00_u4E2Ascalar_uFF09_u2014more_non-linearities_and_deeper_gives_better_results_uFF1A" class="headerlink" title="1.使用小size的filter比使用大size的filter的效果要好得多，小size的filter能够增加non-linearities数，并且能减少需要训练的参数（试想一个7_7的patch，用一个7_7的filter卷积，和用三层的3*3的filter卷积，得到的结果都是一个scalar）—more non-linearities and deeper gives better results："></a>1.使用小size的filter比使用大size的filter的效果要好得多，小size的filter能够增加non-linearities数，并且能减少需要训练的参数（试想一个7_7的patch，用一个7_7的filter卷积，和用三层的3*3的filter卷积，得到的结果都是一个scalar）—more non-linearities and deeper gives better results：</h3><p><img src="http://img.blog.csdn.net/20150811152247024" alt="这里写图片描述"></p>
<h3 id="2-_u4E5F_u53EF_u4EE5_u8BD5_u8BD5_u5728pool_u4E0A_u4E0B_u529F_u592B_uFF1A"><a href="#2-_u4E5F_u53EF_u4EE5_u8BD5_u8BD5_u5728pool_u4E0A_u4E0B_u529F_u592B_uFF1A" class="headerlink" title="2.也可以试试在pool上下功夫："></a>2.也可以试试在pool上下功夫：</h3><p><img src="http://img.blog.csdn.net/20150811152632335" alt="这里写图片描述"></p>
<h3 id="3-Data_Augmentation_uFF1A"><a href="#3-Data_Augmentation_uFF1A" class="headerlink" title="3.Data Augmentation："></a>3.Data Augmentation：</h3><h5 id="u6570_u636E_u96C6_u4E0D_u591F_u7684_u8BDD_uFF0C_u4E5F_u53EF_u4EE5_u8BD5_u8BD5_u7528_u4E0B_u9762_u7684_u51E0_u79CD_u65B9_u5F0F_u6269_u5927_u4F60_u7684_u6570_u636E_u96C6_uFF1A"><a href="#u6570_u636E_u96C6_u4E0D_u591F_u7684_u8BDD_uFF0C_u4E5F_u53EF_u4EE5_u8BD5_u8BD5_u7528_u4E0B_u9762_u7684_u51E0_u79CD_u65B9_u5F0F_u6269_u5927_u4F60_u7684_u6570_u636E_u96C6_uFF1A" class="headerlink" title="数据集不够的话，也可以试试用下面的几种方式扩大你的数据集："></a>数据集不够的话，也可以试试用下面的几种方式扩大你的数据集：</h5><p>####（1）Flip horizontally：可以通过旋转图片来扩大数据集，如果原图像是正方形的话则更好：<br><img src="http://img.blog.csdn.net/20150811153044831" alt="这里写图片描述"></p>
<p>####（2）多尺度切割：多尺度切割不仅能增大数据集，还能提高实现效果，一幅图切割150次都很常见：<br><img src="http://img.blog.csdn.net/20150811153303758" alt="这里写图片描述"></p>
<p>####（3）各种随机组合：<br><img src="http://img.blog.csdn.net/20150812150156002" alt="这里写图片描述"></p>
<p>####（4）Color jittering：<br><img src="http://img.blog.csdn.net/20150812150421669" alt="这里写图片描述"><br>接着上一讲的内容</p>
<h1 id="u516D_uFF1ABeyond_Image_Classification"><a href="#u516D_uFF1ABeyond_Image_Classification" class="headerlink" title="六：Beyond Image Classification"></a>六：Beyond Image Classification</h1><p>###localization－overfeat ：将CNN的最后的softmax层去掉，换做L2 loss，然后微调网络。预测部分，将原来的预测部分换做4-D的向量：<br><img src="http://img.blog.csdn.net/20150813211357016" alt="这里写图片描述"></p>
<p><strong>本文系作者原创，转载请先联系作者: 18254275587@163.com</strong></p>

            
          </span>
        
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2015/10/04/‎Summarize/cnn-for-visual-rcognition-stanford-2015-ef-bc-88-e4-b8-80-ef-bc-89/" itemprop="url">
                  CNN for Visual Rcognition --- Stanford 2015 （一）
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            發表於
            <time itemprop="dateCreated" datetime="2015-10-04T19:37:37+08:00" content="2015-10-04">
              2015-10-04
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp; 分類於
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/Summarize/" itemprop="url" rel="index">
                    <span itemprop="name">Summarize</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

        </div>
      </header>
    


    <div class="post-body">

      
      

      
        
          <span itemprop="articleBody">
            
              <p>总结斯坦福2015李飞飞教授以及Andrej Karpathy教授的上课的slides中关于CNN的一些内容</p>
<h1 id="u4E00_uFF1A_u795E_u7ECF_u7F51_u7EDC_u5B9E_u9A8C_u7684_u57FA_u672C_u7B56_u7565_uFF1A"><a href="#u4E00_uFF1A_u795E_u7ECF_u7F51_u7EDC_u5B9E_u9A8C_u7684_u57FA_u672C_u7B56_u7565_uFF1A" class="headerlink" title="一：神经网络实验的基本策略："></a>一：神经网络实验的基本策略：</h1><p><img src="http://img.blog.csdn.net/20150809150601424" alt="这里写图片描述"></p>
<h3 id="1-_u5BF9_u8F93_u5165_u6570_u636E_u8FDB_u884C_u9884_u5904_u7406_uFF1A"><a href="#1-_u5BF9_u8F93_u5165_u6570_u636E_u8FDB_u884C_u9884_u5904_u7406_uFF1A" class="headerlink" title="1.对输入数据进行预处理："></a>1.对输入数据进行预处理：</h3><p><img src="http://img.blog.csdn.net/20150809113841197" alt="这里写图片描述"><br><img src="http://img.blog.csdn.net/20150809113922745" alt="这里写图片描述"></p>
<h3 id="2-_u7F51_u7EDC_u7ED3_u6784_u548C_u6570_u636E_u96C6_u8BBE_u7F6E_uFF1A"><a href="#2-_u7F51_u7EDC_u7ED3_u6784_u548C_u6570_u636E_u96C6_u8BBE_u7F6E_uFF1A" class="headerlink" title="2.网络结构和数据集设置："></a>2.网络结构和数据集设置：</h3><h4 id="uFF081_uFF09-_u968F_u673A_u521D_u59CB_u5316weights_u4E3A_u4E00_u4E9B_u6BD4_u8F83_u5C0F_u7684_u6570_uFF08fan-in_uFF0Cfan-out_uFF09_uFF0Cbias_u8BBE_u7F6E_u4E3A0"><a href="#uFF081_uFF09-_u968F_u673A_u521D_u59CB_u5316weights_u4E3A_u4E00_u4E9B_u6BD4_u8F83_u5C0F_u7684_u6570_uFF08fan-in_uFF0Cfan-out_uFF09_uFF0Cbias_u8BBE_u7F6E_u4E3A0" class="headerlink" title="（1）-随机初始化weights为一些比较小的数（fan-in，fan-out），bias设置为0"></a>（1）-随机初始化weights为一些比较小的数（fan-in，fan-out），bias设置为0</h4><h4 id="uFF082_uFF09-_u5229_u7528_u597Dcv_u96C6_uFF0C_u53EF_u4EE5_u5728_u5C11_u91CFepoch_u7684_u7ED3_u679C_u4E0B_u9009_u62E9_u6700_u597D_u7684params_uFF0C_u7136_u540E_u8FDB_u884C_u66F4_u591A_u7684epoch"><a href="#uFF082_uFF09-_u5229_u7528_u597Dcv_u96C6_uFF0C_u53EF_u4EE5_u5728_u5C11_u91CFepoch_u7684_u7ED3_u679C_u4E0B_u9009_u62E9_u6700_u597D_u7684params_uFF0C_u7136_u540E_u8FDB_u884C_u66F4_u591A_u7684epoch" class="headerlink" title="（2）-利用好cv集，可以在少量epoch的结果下选择最好的params，然后进行更多的epoch"></a>（2）-利用好cv集，可以在少量epoch的结果下选择最好的params，然后进行更多的epoch</h4><h3 id="3-_u5206_u6790_u5B9E_u9A8C_u7ED3_u679C_uFF1A"><a href="#3-_u5206_u6790_u5B9E_u9A8C_u7ED3_u679C_uFF1A" class="headerlink" title="3.分析实验结果："></a>3.分析实验结果：</h3><h4 id="uFF081_uFF09-_u5BF9_loss_curve__u8FDB_u884C_u5206_u6790_uFF1A"><a href="#uFF081_uFF09-_u5BF9_loss_curve__u8FDB_u884C_u5206_u6790_uFF1A" class="headerlink" title="（1）-对 loss curve 进行分析："></a>（1）-对 loss curve 进行分析：</h4><p><img src="http://img.blog.csdn.net/20150809115128402" alt="这里写图片描述"></p>
<h4 id="uFF082_uFF09-_u5BF9accuracy__u8FDB_u884C_u5206_u6790_uFF1A"><a href="#uFF082_uFF09-_u5BF9accuracy__u8FDB_u884C_u5206_u6790_uFF1A" class="headerlink" title="（2）-对accuracy 进行分析："></a>（2）-对accuracy 进行分析：</h4><p><img src="http://img.blog.csdn.net/20150809115343863" alt="这里写图片描述"></p>
<h4 id="uFF083_uFF09-_u5BF9weight_updates_/_weight_u7684_u6BD4_u503C_u8FDB_u884C_u5206_u6790_uFF1A"><a href="#uFF083_uFF09-_u5BF9weight_updates_/_weight_u7684_u6BD4_u503C_u8FDB_u884C_u5206_u6790_uFF1A" class="headerlink" title="（3）-对weight updates / weight的比值进行分析："></a>（3）-对weight updates / weight的比值进行分析：</h4><p><img src="http://img.blog.csdn.net/20150809120641754" alt="这里写图片描述"></p>
<h4 id="uFF084_uFF09-_u53EF_u89C6_u5316_u9690_u542B_u5C42_u5355_u5143_uFF1A"><a href="#uFF084_uFF09-_u53EF_u89C6_u5316_u9690_u542B_u5C42_u5355_u5143_uFF1A" class="headerlink" title="（4）-可视化隐含层单元："></a>（4）-可视化隐含层单元：</h4><p><img src="http://img.blog.csdn.net/20150809120739397" alt="这里写图片描述"></p>
<h4 id="uFF085_uFF09-dropout_uFF08Regularization_uFF09_u7684_u4F7F_u7528_uFF1A"><a href="#uFF085_uFF09-dropout_uFF08Regularization_uFF09_u7684_u4F7F_u7528_uFF1A" class="headerlink" title="（5）-dropout（Regularization）的使用："></a>（5）-dropout（Regularization）的使用：</h4><h5 id="u968F_u673A_u7684_u5C06_u4E00_u4E9B_neuron_u8BBE_u7F6E_u4E3A0_uFF0C_u5728_u4F7F_u7528_u7684_u65F6_u5019_u6CE8_u610Ftrain_u7684_u65F6_u5019_u548Cpredict_u7684_u65F6_u5019_u7684_u533A_u522B_uFF08train_u7684_u65F6_u5019_u8FDB_u884Cdrop_uFF0Cpredict_u7684_u65F6_u5019_u4E0D_u8FDB_u884Cdrop_uFF09_uFF1A"><a href="#u968F_u673A_u7684_u5C06_u4E00_u4E9B_neuron_u8BBE_u7F6E_u4E3A0_uFF0C_u5728_u4F7F_u7528_u7684_u65F6_u5019_u6CE8_u610Ftrain_u7684_u65F6_u5019_u548Cpredict_u7684_u65F6_u5019_u7684_u533A_u522B_uFF08train_u7684_u65F6_u5019_u8FDB_u884Cdrop_uFF0Cpredict_u7684_u65F6_u5019_u4E0D_u8FDB_u884Cdrop_uFF09_uFF1A" class="headerlink" title="随机的将一些 neuron设置为0，在使用的时候注意train的时候和predict的时候的区别（train的时候进行drop，predict的时候不进行drop）："></a>随机的将一些 neuron设置为0，在使用的时候注意train的时候和predict的时候的区别（train的时候进行drop，predict的时候不进行drop）：</h5><p><img src="http://img.blog.csdn.net/20150809121143317" alt="这里写图片描述"><br><img src="http://img.blog.csdn.net/20150809121212774" alt="这里写图片描述"></p>
<h4 id="uFF086_uFF09-_u5B66_u4E60_u7387_u7B49_u76F8_u5173_u8BBE_u7F6E_uFF1A"><a href="#uFF086_uFF09-_u5B66_u4E60_u7387_u7B49_u76F8_u5173_u8BBE_u7F6E_uFF1A" class="headerlink" title="（6）-学习率等相关设置："></a>（6）-学习率等相关设置：</h4><p><img src="http://img.blog.csdn.net/20150809121448010" alt="这里写图片描述"><br>一般用写好的库就行了，如adagrad等等</p>
<h1 id="u4E8C_uFF1A_u5377_u79EF_u7F51_u7EDCConVNet_uFF1A"><a href="#u4E8C_uFF1A_u5377_u79EF_u7F51_u7EDCConVNet_uFF1A" class="headerlink" title="二：卷积网络ConVNet："></a>二：卷积网络ConVNet：</h1><p><img src="http://img.blog.csdn.net/20150809121730285" alt="这里写图片描述"></p>
<h3 id="1-activations_uFF1A"><a href="#1-activations_uFF1A" class="headerlink" title="1.activations："></a>1.activations：</h3><h4 id="ConVNet_u4E2D_u7684activations_u662F_u4E00_u4E2A_u4E09_u7EF4_u7684_u7ACB_u65B9_u4F53_uFF0C_u4F8B_u5982_uFF1A_u5BF9_u4E8E_u4E00_u4E2A32_32_3_u7684RGB_u56FE_u7247_uFF0C_u5BF9_u5E94_u7684activation_u7684_u89C4_u683C_u5C31_u662F32widt_32height_3depth"><a href="#ConVNet_u4E2D_u7684activations_u662F_u4E00_u4E2A_u4E09_u7EF4_u7684_u7ACB_u65B9_u4F53_uFF0C_u4F8B_u5982_uFF1A_u5BF9_u4E8E_u4E00_u4E2A32_32_3_u7684RGB_u56FE_u7247_uFF0C_u5BF9_u5E94_u7684activation_u7684_u89C4_u683C_u5C31_u662F32widt_32height_3depth" class="headerlink" title="ConVNet中的activations是一个三维的立方体，例如：对于一个32_32_3的RGB图片，对应的activation的规格就是32widt_32height_3depth"></a>ConVNet中的activations是一个三维的立方体，例如：对于一个32_32_3的RGB图片，对应的activation的规格就是32widt_32height_3depth</h4><p><img src="http://img.blog.csdn.net/20150809142934093" alt="这里写图片描述"></p>
<h3 id="2-local_connectivity__u5C40_u90E8_u8FDE_u63A5_uFF1A"><a href="#2-local_connectivity__u5C40_u90E8_u8FDE_u63A5_uFF1A" class="headerlink" title="2.local connectivity 局部连接："></a>2.local connectivity 局部连接：</h3><h4 id="uFF081_uFF09-_u5C40_u90E8_u8FDE_u63A5_u662FConVNet_u4E00_u4E2A_u5F88_u91CD_u8981_u7684_u601D_u60F3_uFF0C_u4F7F_u7528_u5C40_u90E8_u8FDE_u63A5_uFF0C_u51CF_u5C11_u4E86_u5377_u79EF_u5C42_u9700_u8981_u8BAD_u7EC3_u7684params_uFF1A"><a href="#uFF081_uFF09-_u5C40_u90E8_u8FDE_u63A5_u662FConVNet_u4E00_u4E2A_u5F88_u91CD_u8981_u7684_u601D_u60F3_uFF0C_u4F7F_u7528_u5C40_u90E8_u8FDE_u63A5_uFF0C_u51CF_u5C11_u4E86_u5377_u79EF_u5C42_u9700_u8981_u8BAD_u7EC3_u7684params_uFF1A" class="headerlink" title="（1）-局部连接是ConVNet一个很重要的思想，使用局部连接，减少了卷积层需要训练的params："></a>（1）-局部连接是ConVNet一个很重要的思想，使用局部连接，减少了卷积层需要训练的params：</h4><p><img src="http://img.blog.csdn.net/20150809144048891" alt="这里写图片描述"></p>
<h4 id="uFF082_uFF09-_u4E3E_u4E2A_u6817_u5B50_uFF1A"><a href="#uFF082_uFF09-_u4E3E_u4E2A_u6817_u5B50_uFF1A" class="headerlink" title="（2）-举个栗子：<img src=" http:="" img.blog.csdn.net="" 20150809144229995"="" alt="这里写图片描述">"></a>（2）-举个栗子：<img src="http://img.blog.csdn.net/20150809144229995" alt="这里写图片描述"></h4><h4 id="uFF083_uFF09-_u672F_u8BED_u4E0A_uFF1Afenture_map_u4E2A_u6570_3Dfilter_u4E2A_u6570"><a href="#uFF083_uFF09-_u672F_u8BED_u4E0A_uFF1Afenture_map_u4E2A_u6570_3Dfilter_u4E2A_u6570" class="headerlink" title="（3）-术语上：fenture map个数=filter个数"></a>（3）-术语上：fenture map个数=filter个数</h4><h3 id="3-padding_uFF1A"><a href="#3-padding_uFF1A" class="headerlink" title="3.padding："></a>3.padding：</h3><h4 id="u589E_u52A0nolinearities_u7684_u6570_u91CF_uFF0C_u540C_u65F6_u4E5F_u53EF_u4EE5_u4FDD_u6301map_u7684_u5927_u5C0F_uFF1A"><a href="#u589E_u52A0nolinearities_u7684_u6570_u91CF_uFF0C_u540C_u65F6_u4E5F_u53EF_u4EE5_u4FDD_u6301map_u7684_u5927_u5C0F_uFF1A" class="headerlink" title="增加nolinearities的数量，同时也可以保持map的大小："></a>增加nolinearities的数量，同时也可以保持map的大小：</h4><p><img src="http://img.blog.csdn.net/20150809145227547" alt="这里写图片描述"></p>
<h3 id="4-pooling_uFF1A"><a href="#4-pooling_uFF1A" class="headerlink" title="4.pooling："></a>4.pooling：</h3><h4 id="u4E00_u822C_u662F2*2_u7684maxpool_uFF1A"><a href="#u4E00_u822C_u662F2*2_u7684maxpool_uFF1A" class="headerlink" title="一般是2*2的maxpool："></a>一般是2*2的maxpool：</h4><p><img src="http://img.blog.csdn.net/20150809145628112" alt="这里写图片描述"></p>
<h3 id="5-ConVNet_u7684_u8BBE_u7F6E_uFF1A"><a href="#5-ConVNet_u7684_u8BBE_u7F6E_uFF1A" class="headerlink" title="5.ConVNet的设置："></a>5.ConVNet的设置：</h3><p><img src="http://img.blog.csdn.net/20150809145749823" alt="这里写图片描述"></p>
<h1 id="u4E09_uFF1AVisualizing_and_Understanding_ConVNet_uFF1A"><a href="#u4E09_uFF1AVisualizing_and_Understanding_ConVNet_uFF1A" class="headerlink" title="三：Visualizing and Understanding ConVNet："></a>三：Visualizing and Understanding ConVNet：</h1><p><img src="http://img.blog.csdn.net/20150809150512443" alt="这里写图片描述"></p>
<h3 id="1-t-SNE_visualization_uFF1A"><a href="#1-t-SNE_visualization_uFF1A" class="headerlink" title="1.t-SNE visualization："></a>1.t-SNE visualization：</h3><h4 id="u4E0B_u56FE_u662Fmnist_u6570_u636E_u96C6_u901A_u8FC7ConVNet_u540E_u538B_u7F29_u6210_u4E8C_u7EF4_u5411_u91CF_u540E_u7684_u70B9_u56FE_uFF1A"><a href="#u4E0B_u56FE_u662Fmnist_u6570_u636E_u96C6_u901A_u8FC7ConVNet_u540E_u538B_u7F29_u6210_u4E8C_u7EF4_u5411_u91CF_u540E_u7684_u70B9_u56FE_uFF1A" class="headerlink" title="下图是mnist数据集通过ConVNet后压缩成二维向量后的点图："></a>下图是mnist数据集通过ConVNet后压缩成二维向量后的点图：</h4><p><img src="http://img.blog.csdn.net/20150809151212093" alt="这里写图片描述"></p>
<h3 id="2-_u5C06_u6700_u540E_u7684pooling_u5C42_u7684_u7279_u5F81_uFF0C_u91CD_u6784_u6210_u56FE_u7247_uFF1A"><a href="#2-_u5C06_u6700_u540E_u7684pooling_u5C42_u7684_u7279_u5F81_uFF0C_u91CD_u6784_u6210_u56FE_u7247_uFF1A" class="headerlink" title="2.将最后的pooling层的特征，重构成图片："></a>2.将最后的pooling层的特征，重构成图片：</h3><p><img src="http://img.blog.csdn.net/20150809195717575" alt="这里写图片描述"></p>
<h3 id="3-_u5C06_u4E2D_u95F4_u5C42_u7684_u7279_u5F81_uFF0C_u91CD_u6784_u6210_u56FE_u7247_uFF1A"><a href="#3-_u5C06_u4E2D_u95F4_u5C42_u7684_u7279_u5F81_uFF0C_u91CD_u6784_u6210_u56FE_u7247_uFF1A" class="headerlink" title="3.将中间层的特征，重构成图片："></a>3.将中间层的特征，重构成图片：</h3><p><img src="http://img.blog.csdn.net/20150809195935394" alt="这里写图片描述"></p>
<h3 id="4-_u5BF9_u4E8E_u4E0D_u53EF_u8BC6_u522B_u7684_u56FE_u7247_uFF0CConVNet_u6709_u65F6_u7ADF_u7136_u4F1A_u6709_u5F88_u9AD8_u7684_u7F6E_u4FE1_u5EA6_uFF1A"><a href="#4-_u5BF9_u4E8E_u4E0D_u53EF_u8BC6_u522B_u7684_u56FE_u7247_uFF0CConVNet_u6709_u65F6_u7ADF_u7136_u4F1A_u6709_u5F88_u9AD8_u7684_u7F6E_u4FE1_u5EA6_uFF1A" class="headerlink" title="4.对于不可识别的图片，ConVNet有时竟然会有很高的置信度："></a>4.对于不可识别的图片，ConVNet有时竟然会有很高的置信度：</h3><p><img src="http://img.blog.csdn.net/20150809200356803" alt="这里写图片描述"></p>
<h3 id="5-depth_is_important_3A"><a href="#5-depth_is_important_3A" class="headerlink" title="5.depth is important:"></a>5.depth is important:</h3><h4 id="u6539_u53D8FC_u5C42_u7684_u5927_u5C0F_uFF0C_u5BF9_u7ED3_u679C_u5E76_u6CA1_u6709_u591A_u5927_u7684_u63D0_u5347_uFF1B_u800C_u901A_u8FC7_u6539_u53D8_u5377_u79EF_u5C42depth_u7684_u5927_u5C0F_uFF08_u5176_u5B9E_u5C31_u662Ffilter_u7684_u6570_u91CF_uFF09_uFF0C_u5219_u5BF9_u7ED3_u679C_u6709_u8F83_u5927_u7684_u5F71_u54CD_uFF0C_u5E76_u4E14_uFF1Amore_depth__3D_better_improvement_u3002"><a href="#u6539_u53D8FC_u5C42_u7684_u5927_u5C0F_uFF0C_u5BF9_u7ED3_u679C_u5E76_u6CA1_u6709_u591A_u5927_u7684_u63D0_u5347_uFF1B_u800C_u901A_u8FC7_u6539_u53D8_u5377_u79EF_u5C42depth_u7684_u5927_u5C0F_uFF08_u5176_u5B9E_u5C31_u662Ffilter_u7684_u6570_u91CF_uFF09_uFF0C_u5219_u5BF9_u7ED3_u679C_u6709_u8F83_u5927_u7684_u5F71_u54CD_uFF0C_u5E76_u4E14_uFF1Amore_depth__3D_better_improvement_u3002" class="headerlink" title="改变FC层的大小，对结果并没有多大的提升；而通过改变卷积层depth的大小（其实就是filter的数量），则对结果有较大的影响，并且：more depth = better improvement。"></a>改变FC层的大小，对结果并没有多大的提升；而通过改变卷积层depth的大小（其实就是filter的数量），则对结果有较大的影响，并且：more depth = better improvement。</h4><p>normalization对结果也没有很大的影响</p>
<p><strong>本文系作者原创，转载请先联系作者: 18254275587@163.com</strong></p>

            
          </span>
        
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2015/10/04/‎Summarize/e6-b5-85-e6-9e-90sae-e4-b8-8edbm-ef-bc-88deep-learning-ef-bc-89/" itemprop="url">
                  浅析SAE与DBM（Deep Learning）
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            發表於
            <time itemprop="dateCreated" datetime="2015-10-04T19:36:46+08:00" content="2015-10-04">
              2015-10-04
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp; 分類於
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/Summarize/" itemprop="url" rel="index">
                    <span itemprop="name">Summarize</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

        </div>
      </header>
    


    <div class="post-body">

      
      

      
        
          <span itemprop="articleBody">
            
              <p>SAE与DBM两个都可以用于提取输入集特征。</p>
<h1 id="SAE"><a href="#SAE" class="headerlink" title="SAE"></a>SAE</h1><p>SAE是由多个Spase AutoEncoder堆叠而成，单个Spase AutoEncoder的结构如下：<br>    <img src="http://img.blog.csdn.net/20150525111718774" alt=""><br>    在堆叠成SAE时的结构如下：<br>    <img src="http://img.blog.csdn.net/20150525111851522" alt=""><br>    以上SAE的结构可以化分为两个sparse autoencoder和一个 softmax（这里不讨论softmax）.其中的两个sparse autoencoder结构如图：<br>    第一层：<img src="http://img.blog.csdn.net/20150525112200797" alt=""><br>   第二层：<img src="http://img.blog.csdn.net/20150525112424670" alt=""><br>   在训练SAE的时候，也是一层一层的进行训练，首先将原始数据输入训练第一层sparse autoencoder，获得了第一层的features（也就是训练获得的参数权重W1和偏置b1），而后根据：<br>                           z2 = W1*data+repmat(b1,1,m);<br>            activation = sigmoid(z2);<br>获得activation作为输入训练第二层sparse autoencoder，以此类推。</p>
<h1 id="DBM"><a href="#DBM" class="headerlink" title="DBM"></a>DBM</h1><p>DBM可以说是由多个RBM叠加起来的（注意与DBM的区别）。<br>  DBM由多层神经元构成，这些神经元又分为显性神经元和隐性神经元（以下简称显元和隐元）。显元用于接受输入，隐元用于提取特征。因此隐元也有个别名，叫特征检测器 (feature detectors)。最顶上的两层间的连接是无向的，组成联合内存 (associative memory)。较低的其他层之间有连接上下的有向连接。最底层代表了数据向量 (data vectors)，每一个神经元代表数据向量的一维。<br>DBM 的组成元件是受限玻尔兹曼机 (Restricted Boltzmann Machines, RBM)。训练 DBM 的过程是一层一层地进行的。在每一层中，用数据向量来推断隐层，再把这一隐层当作下一层 (高一层) 的数据向量。</p>
<p>RBM 的训练过程，实际上是求出一个最能产生训练样本的概率分布。<br>RBM：<img src="http://img.blog.csdn.net/20150525120641459" alt=""></p>
<h1 id="u603B_u7ED3"><a href="#u603B_u7ED3" class="headerlink" title="总结"></a>总结</h1><p>sae是非线性变换找到主特征方向，而dbm是基于样本的概率分布来提取高层表示。两者的的基本单元sparse autoencoder和rbm的基本原理是不同的。训练方法上，sae一般用梯度下降方法，而dbm则是kl散度。sae和dbm训练的整体流程都是一致的，都是一层一层进行训练。</p>
<p><strong>本文作者原创，转载请先联系作者: 18254275587@163.com</strong></p>

            
          </span>
        
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2015/10/04/papers/spatial-pyramid-pooling-in-deep-convolutional-spp-net/" itemprop="url">
                  Spatial Pyramid Pooling in Deep Convolutional --- Spp_net
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            發表於
            <time itemprop="dateCreated" datetime="2015-10-04T19:34:17+08:00" content="2015-10-04">
              2015-10-04
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp; 分類於
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/papers/" itemprop="url" rel="index">
                    <span itemprop="name">papers</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

        </div>
      </header>
    


    <div class="post-body">

      
      

      
        
          <span itemprop="articleBody">
            
              <p>微软亚研院2015的一篇文章，优点是能够满足任意大小图像的输入。</p>
<h1 id="u4E3B_u8981_u601D_u60F3_uFF1A"><a href="#u4E3B_u8981_u601D_u60F3_uFF1A" class="headerlink" title="主要思想："></a>主要思想：</h1><h3 id="uFF081_uFF09Spatial_Pyramid_Pooling_Layer-__u6B63_u662F_u56E0_u4E3A_u8BE5_u5C42_uFF0C_u624D_u8BA9Spp_net_u80FD_u591F_u5B9E_u73B0_u4EFB_u610F_u56FE_u7247_u7684_u8F93_u5165_uFF0C_u5E76_u4E14_u5F97_u5230_u56FA_u5B9A_u957F_u5EA6_u7684_u7279_u5F81_u5411_u91CF_uFF1A"><a href="#uFF081_uFF09Spatial_Pyramid_Pooling_Layer-__u6B63_u662F_u56E0_u4E3A_u8BE5_u5C42_uFF0C_u624D_u8BA9Spp_net_u80FD_u591F_u5B9E_u73B0_u4EFB_u610F_u56FE_u7247_u7684_u8F93_u5165_uFF0C_u5E76_u4E14_u5F97_u5230_u56FA_u5B9A_u957F_u5EA6_u7684_u7279_u5F81_u5411_u91CF_uFF1A" class="headerlink" title="（1）Spatial Pyramid Pooling Layer. 正是因为该层，才让Spp_net能够实现任意图片的输入，并且得到固定长度的特征向量："></a>（1）Spatial Pyramid Pooling Layer. 正是因为该层，才让Spp_net能够实现任意图片的输入，并且得到固定长度的特征向量：</h3><p><img src="http://img.blog.csdn.net/20150901145828613" alt="这里写图片描述"></p>
<h3 id="stride_u548Cwindow_u7684_u8BA1_u7B97_uFF1A"><a href="#stride_u548Cwindow_u7684_u8BA1_u7B97_uFF1A" class="headerlink" title="stride和window的计算："></a>stride和window的计算：</h3><p><img src="http://img.blog.csdn.net/20150929192305267" alt="这里写图片描述"></p>
<h3 id="uFF082_uFF09Mapping_a_Window_to_Feature_Maps-__u5C06_u539F_u56FE_u8F93_u5165Spp_net_u540E_uFF0C_u901A_u8FC7_u4E0B_u9762_u56FE_u7247_u4E2D_u4ECB_u7ECD_u7684_u65B9_u6CD5_uFF0C_u80FD_u591F_u5C06_u539F_u56FE_u4E2D_u7684_u70B9_u6620_u5C04_u5230feature_map_u4E0A_uFF0C_u4E3Aobject_detection_u6253_u4E0B_u57FA_u7840_uFF1A"><a href="#uFF082_uFF09Mapping_a_Window_to_Feature_Maps-__u5C06_u539F_u56FE_u8F93_u5165Spp_net_u540E_uFF0C_u901A_u8FC7_u4E0B_u9762_u56FE_u7247_u4E2D_u4ECB_u7ECD_u7684_u65B9_u6CD5_uFF0C_u80FD_u591F_u5C06_u539F_u56FE_u4E2D_u7684_u70B9_u6620_u5C04_u5230feature_map_u4E0A_uFF0C_u4E3Aobject_detection_u6253_u4E0B_u57FA_u7840_uFF1A" class="headerlink" title="（2）Mapping a Window to Feature Maps. 将原图输入Spp_net后，通过下面图片中介绍的方法，能够将原图中的点映射到feature map上，为object detection打下基础："></a>（2）Mapping a Window to Feature Maps. 将原图输入Spp_net后，通过下面图片中介绍的方法，能够将原图中的点映射到feature map上，为object detection打下基础：</h3><p><img src="http://img.blog.csdn.net/20150901150356441" alt="这里写图片描述"></p>
<h1 id="u4E3B_u8981_u4EE3_u7801_u5B9E_u73B0_uFF08_u57FA_u4E8Etheano/keras_uFF09_uFF1A"><a href="#u4E3B_u8981_u4EE3_u7801_u5B9E_u73B0_uFF08_u57FA_u4E8Etheano/keras_uFF09_uFF1A" class="headerlink" title="主要代码实现（基于theano/keras）："></a>主要代码实现（基于theano/keras）：</h1><h3 id="uFF081_uFF09spp_layer_3A"><a href="#uFF081_uFF09spp_layer_3A" class="headerlink" title="（1）spp_layer:"></a>（1）spp_layer:</h3><pre><code>def __init__(self,bins,feature_map_size=0):
    super(SppLayer,self).__init__()
    self.strides = []
    self.windows = []
    self.a = feature_map_size#feature_map size
    self.bins = bins
    self.num_bins = len(bins)

def get_output(self,train):
    self.input = self.get_input(train)
    for i in range(self.num_bins):
        self.strides.append(int(math.floor(self.a/self.bins[i])))
        self.windows.append(int(math.ceil(self.a/self.bins[i])))

    self.pooled_out = []
    for j in range(self.num_bins):
        self.pooled_out.append(downsample.max_pool_2d(input=self.input,
                                                          ds=(self.windows[j],self.windows[j]),
                                                          st=(self.strides[j],self.strides[j]),
                                                          ignore_border=False))

    for k in range(self.num_bins):
        self.pooled_out[k] = self.pooled_out[k].flatten(2)
        &amp;quot;&amp;quot;&amp;quot;
        print self.windows[k]
        print self.strides[k]
        print &amp;#039;K: &amp;#039;+str(k)
        &amp;quot;&amp;quot;&amp;quot;
    # batch_size * image_size
    self.output = T.concatenate([self.pooled_out[0],self.pooled_out[1],self.pooled_out[2]],axis=1)

    return self.output
</code></pre><h3 id="282_29Mapping_a_Window_to_Feature_Maps_3A"><a href="#282_29Mapping_a_Window_to_Feature_Maps_3A" class="headerlink" title="(2)Mapping a Window to Feature Maps:"></a>(2)Mapping a Window to Feature Maps:</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">window_t</span><span class="params">(window_point_x1,window_point_y1,window_point_x2,window_point_y2,</span><br><span class="line">                         window_size_x,window_size_y,map_size_x,map_size_y)</span>:</span></span><br><span class="line">   	map_point_x1 = window_point_x1*math.ceil(map_size_x/window_size_x)-<span class="number">1</span></span><br><span class="line">   	map_point_y1 = window_point_y1*math.ceil(map_size_y/window_size_y)-<span class="number">1</span></span><br><span class="line">   	map_point_x2 = window_point_x2*math.ceil(map_size_x/window_size_x)-<span class="number">1</span></span><br><span class="line">   	map_point_y2 = window_point_y2*math.ceil(map_size_y/window_size_y)-<span class="number">1</span></span><br><span class="line"></span><br><span class="line">   	<span class="keyword">return</span> map_point_x1,map_point_y1,map_point_x2,map_point_y2</span><br></pre></td></tr></table></figure>
<p><strong>本文系作者原创，转载请先联系作者: 18254275587@163.com</strong></p>

            
          </span>
        
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2015/10/04/papers/batch-normalization-e7-ae-80-e5-8d-95-e7-90-86-e8-a7-a3/" itemprop="url">
                  Batch Normalization 简单理解
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            發表於
            <time itemprop="dateCreated" datetime="2015-10-04T19:32:05+08:00" content="2015-10-04">
              2015-10-04
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp; 分類於
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/papers/" itemprop="url" rel="index">
                    <span itemprop="name">papers</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

        </div>
      </header>
    


    <div class="post-body">

      
      

      
        
          <span itemprop="articleBody">
            
              <h1 id="1_uFF1A_u80CC_u666F"><a href="#1_uFF1A_u80CC_u666F" class="headerlink" title="1：背景"></a>1：背景</h1><h3 id="u7531_u4E8E_u5728_u8BAD_u7EC3_u795E_u7ECF_u7F51_u7EDC_u7684_u8FC7_u7A0B_u4E2D_uFF0C_u6BCF_u4E00_u5C42_u7684_params_u662F_u4E0D_u65AD_u66F4_u65B0_u7684_uFF0C_u7531_u4E8Eparams_u7684_u66F4_u65B0_u4F1A_u5BFC_u81F4_u4E0B_u4E00_u5C42_u8F93_u5165_u7684_u5206_u5E03_u60C5_u51B5_u53D1_u751F_u6539_u53D8_uFF0C_u6240_u4EE5_u8FD9_u5C31_u8981_u6C42_u6211_u4EEC_u8FDB_u884C_u6743_u91CD_u521D_u59CB_u5316_uFF0C_u51CF_u5C0F_u5B66_u4E60_u7387_u3002_u8FD9_u4E2A_u73B0_u8C61_u5C31_u53EB_u505Ainternal_covariate_shift_u3002"><a href="#u7531_u4E8E_u5728_u8BAD_u7EC3_u795E_u7ECF_u7F51_u7EDC_u7684_u8FC7_u7A0B_u4E2D_uFF0C_u6BCF_u4E00_u5C42_u7684_params_u662F_u4E0D_u65AD_u66F4_u65B0_u7684_uFF0C_u7531_u4E8Eparams_u7684_u66F4_u65B0_u4F1A_u5BFC_u81F4_u4E0B_u4E00_u5C42_u8F93_u5165_u7684_u5206_u5E03_u60C5_u51B5_u53D1_u751F_u6539_u53D8_uFF0C_u6240_u4EE5_u8FD9_u5C31_u8981_u6C42_u6211_u4EEC_u8FDB_u884C_u6743_u91CD_u521D_u59CB_u5316_uFF0C_u51CF_u5C0F_u5B66_u4E60_u7387_u3002_u8FD9_u4E2A_u73B0_u8C61_u5C31_u53EB_u505Ainternal_covariate_shift_u3002" class="headerlink" title="由于在训练神经网络的过程中，每一层的 params是不断更新的，由于params的更新会导致下一层输入的分布情况发生改变，所以这就要求我们进行权重初始化，减小学习率。这个现象就叫做internal covariate shift。"></a>由于在训练神经网络的过程中，每一层的 params是不断更新的，由于params的更新会导致下一层输入的分布情况发生改变，所以这就要求我们进行权重初始化，减小学习率。这个现象就叫做internal covariate shift。</h3><h1 id="2_uFF1Aidea_u601D_u60F3"><a href="#2_uFF1Aidea_u601D_u60F3" class="headerlink" title="2：idea思想"></a>2：idea思想</h1><h3 id="u867D_u7136_u53EF_u4EE5_u901A_u8FC7whitening_u6765_u52A0_u901F_u6536_u655B_uFF0C_u4F46_u662F_u9700_u8981_u7684_u8BA1_u7B97_u8D44_u6E90_u4F1A_u5F88_u5927_u3002"><a href="#u867D_u7136_u53EF_u4EE5_u901A_u8FC7whitening_u6765_u52A0_u901F_u6536_u655B_uFF0C_u4F46_u662F_u9700_u8981_u7684_u8BA1_u7B97_u8D44_u6E90_u4F1A_u5F88_u5927_u3002" class="headerlink" title="虽然可以通过whitening来加速收敛，但是需要的计算资源会很大。"></a>虽然可以通过whitening来加速收敛，但是需要的计算资源会很大。</h3><h3 id="u800CBatch_Normalizationn_u7684_u601D_u60F3_u5219_u662F_u5BF9_u4E8E_u6BCF_u4E00_u7EC4batch_uFF0C_u5728_u7F51_u7EDC_u7684_u6BCF_u4E00_u5C42_u4E2D_uFF0C_u5206feature_u5BF9_u8F93_u5165_u8FDB_u884Cnormalization_uFF0C_u5BF9_u5404_u4E2Afeature_u5206_u522Bnormalization_uFF0C_u5373_u5BF9_u7F51_u7EDC_u4E2D_u6BCF_u4E00_u5C42_u7684_u5355_u4E2A_u795E_u7ECF_u5143_u8F93_u5165_uFF0C_u8BA1_u7B97_u5747_u503C_u548C_u65B9_u5DEE_u540E_uFF0C_u518D_u8FDB_u884Cnormalization_u3002"><a href="#u800CBatch_Normalizationn_u7684_u601D_u60F3_u5219_u662F_u5BF9_u4E8E_u6BCF_u4E00_u7EC4batch_uFF0C_u5728_u7F51_u7EDC_u7684_u6BCF_u4E00_u5C42_u4E2D_uFF0C_u5206feature_u5BF9_u8F93_u5165_u8FDB_u884Cnormalization_uFF0C_u5BF9_u5404_u4E2Afeature_u5206_u522Bnormalization_uFF0C_u5373_u5BF9_u7F51_u7EDC_u4E2D_u6BCF_u4E00_u5C42_u7684_u5355_u4E2A_u795E_u7ECF_u5143_u8F93_u5165_uFF0C_u8BA1_u7B97_u5747_u503C_u548C_u65B9_u5DEE_u540E_uFF0C_u518D_u8FDB_u884Cnormalization_u3002" class="headerlink" title="而Batch Normalizationn的思想则是对于每一组batch，在网络的每一层中，分feature对输入进行normalization，对各个feature分别normalization，即对网络中每一层的单个神经元输入，计算均值和方差后，再进行normalization。"></a>而Batch Normalizationn的思想则是对于每一组batch，在网络的每一层中，分feature对输入进行normalization，对各个feature分别normalization，即对网络中每一层的单个神经元输入，计算均值和方差后，再进行normalization。</h3><h3 id="u5BF9_u4E8ECNN_u6765_u8BF4normalize__u201CWx+b_u201D_u800C_u975E__u201Cx_u201D_uFF0C_u4E5F_u53EF_u4EE5_u5FFD_u7565_u6389b_uFF0C_u5373normalize__u201CWx_u201D_uFF0C_u800C_u8BA1_u7B97_u5747_u503C_u548C_u65B9_u5DEE_u7684_u65F6_u5019_uFF0C_u662F_u5728feature_map_u7684_u57FA_u7840_u4E0A_uFF08_u539F_u6765_u662F_u6BCF_u4E00_u4E2Afeature_uFF09"><a href="#u5BF9_u4E8ECNN_u6765_u8BF4normalize__u201CWx+b_u201D_u800C_u975E__u201Cx_u201D_uFF0C_u4E5F_u53EF_u4EE5_u5FFD_u7565_u6389b_uFF0C_u5373normalize__u201CWx_u201D_uFF0C_u800C_u8BA1_u7B97_u5747_u503C_u548C_u65B9_u5DEE_u7684_u65F6_u5019_uFF0C_u662F_u5728feature_map_u7684_u57FA_u7840_u4E0A_uFF08_u539F_u6765_u662F_u6BCF_u4E00_u4E2Afeature_uFF09" class="headerlink" title="对于CNN来说normalize “Wx+b”而非 “x”，也可以忽略掉b，即normalize “Wx”，而计算均值和方差的时候，是在feature map的基础上（原来是每一个feature）"></a>对于CNN来说normalize “Wx+b”而非 “x”，也可以忽略掉b，即normalize “Wx”，而计算均值和方差的时候，是在feature map的基础上（原来是每一个feature）</h3><h1 id="3_uFF1A_u7B97_u6CD5_u6D41_u7A0B_uFF08_u5BF9network_u8FDB_u884Cnormalize_uFF09"><a href="#3_uFF1A_u7B97_u6CD5_u6D41_u7A0B_uFF08_u5BF9network_u8FDB_u884Cnormalize_uFF09" class="headerlink" title="3：算法流程（对network进行normalize）"></a>3：算法流程（对network进行normalize）</h1><h3 id="u7B97_u6CD5_u4E00"><a href="#u7B97_u6CD5_u4E00" class="headerlink" title="算法一"></a>算法一</h3><p><img src="http://img.blog.csdn.net/20150923144511118" alt="这里写图片描述"></p>
<h3 id="u7B97_u6CD5_u4E8C"><a href="#u7B97_u6CD5_u4E8C" class="headerlink" title="算法二"></a>算法二</h3><p><img src="http://img.blog.csdn.net/20150923144548232" alt="这里写图片描述"></p>
<h1 id="4_uFF1A_u4EE3_u7801_uFF08keras_uFF09"><a href="#4_uFF1A_u4EE3_u7801_uFF08keras_uFF09" class="headerlink" title="4：代码（keras）"></a>4：代码（keras）</h1><pre><code>&apos;&apos;&apos;
    Reference:
        Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift
            http://arxiv.org/pdf/1502.03167v3.pdf
        mode: 0 -&gt; featurewise normalization
              1 -&gt; samplewise normalization (may sometimes outperform featurewise mode)
        momentum: momentum term in the computation of a running estimate of the mean and std of the data
&apos;&apos;&apos;
def __init__(self, input_shape, epsilon=1e-6, mode=0, momentum=0.9, weights=None):
    super(BatchNormalization, self).__init__()
    self.init = initializations.get(&quot;uniform&quot;)
    self.input_shape = input_shape
    self.epsilon = epsilon
    self.mode = mode
    self.momentum = momentum
    self.input = ndim_tensor(len(self.input_shape) + 1)

    self.gamma = self.init((self.input_shape))
    self.beta = shared_zeros(self.input_shape)

    self.params = [self.gamma, self.beta]
    self.running_mean = shared_zeros(self.input_shape)
    self.running_std = shared_ones((self.input_shape))
    if weights is not None:
        self.set_weights(weights)

def get_weights(self):
    return super(BatchNormalization, self).get_weights() + [self.running_mean.get_value(), self.running_std.get_value()]

def set_weights(self, weights):
    self.running_mean.set_value(floatX(weights[-2]))
    self.running_std.set_value(floatX(weights[-1]))
    super(BatchNormalization, self).set_weights(weights[:-2])

def init_updates(self):
    X = self.get_input(train=True)
    m = X.mean(axis=0)
    std = T.mean((X - m) ** 2 + self.epsilon, axis=0) ** 0.5
    mean_update = self.momentum * self.running_mean + (1-self.momentum) * m
    std_update = self.momentum * self.running_std + (1-self.momentum) * std
    self.updates = [(self.running_mean, mean_update), (self.running_std, std_update)]

def get_output(self, train):
    X = self.get_input(train)

    if self.mode == 0:
        X_normed = (X - self.running_mean) / (self.running_std + self.epsilon)

    elif self.mode == 1:
        m = X.mean(axis=-1, keepdims=True)
        std = X.std(axis=-1, keepdims=True)
        X_normed = (X - m) / (std + self.epsilon)

    out = self.gamma * X_normed + self.beta
    return out

def get_config(self):
    return {&quot;name&quot;: self.__class__.__name__,
            &quot;input_shape&quot;: self.input_shape,
            &quot;epsilon&quot;: self.epsilon,
            &quot;mode&quot;: self.mode}
</code></pre><p><strong>本文系作者原创，转载请先联系作者: 18254275587@163.com</strong></p>

            
          </span>
        
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2015/10/04/papers/learning-both-weights-and-connections-for-efficient-neural-network-e8-ae-ba-e6-96-87-e7-ac-94-e8-ae-b0/" itemprop="url">
                  Learning both Weights and Connections for Efficient Neural Network -- 论文笔记
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            發表於
            <time itemprop="dateCreated" datetime="2015-10-04T19:31:01+08:00" content="2015-10-04">
              2015-10-04
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp; 分類於
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/papers/" itemprop="url" rel="index">
                    <span itemprop="name">papers</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

        </div>
      </header>
    


    <div class="post-body">

      
      

      
        
          <span itemprop="articleBody">
            
              <p>这是2015年斯坦福和英伟达的一篇论文。</p>
<h1 id="1-_u7B80_u4ECB_uFF1A"><a href="#1-_u7B80_u4ECB_uFF1A" class="headerlink" title="1.简介："></a>1.简介：</h1><h2 id="u901A_u8FC7_u4FEE_u526A_u8BAD_u7EC3_u540E_u7F51_u7EDC_u4E2D_u7684_u4E0D_u91CD_u8981_u8FDE_u63A5_uFF08connections_uFF09_uFF0C_u6765_u51CF_u5C11_u7F51_u7EDC_u6240_u9700_u8981_u7684_u53C2_u6570_uFF0C_u51CF_u5C11_u5185_u5B58_u548Ccpu_u7684_u6D88_u8017_uFF0C_u4F7F_u7F51_u7EDC_u66F4_u52A0_u9002_u5E94_u5728_u79FB_u52A8_u8BBE_u5907_u4E0A_u8FD0_u884C_u3002"><a href="#u901A_u8FC7_u4FEE_u526A_u8BAD_u7EC3_u540E_u7F51_u7EDC_u4E2D_u7684_u4E0D_u91CD_u8981_u8FDE_u63A5_uFF08connections_uFF09_uFF0C_u6765_u51CF_u5C11_u7F51_u7EDC_u6240_u9700_u8981_u7684_u53C2_u6570_uFF0C_u51CF_u5C11_u5185_u5B58_u548Ccpu_u7684_u6D88_u8017_uFF0C_u4F7F_u7F51_u7EDC_u66F4_u52A0_u9002_u5E94_u5728_u79FB_u52A8_u8BBE_u5907_u4E0A_u8FD0_u884C_u3002" class="headerlink" title="通过修剪训练后网络中的不重要连接（connections），来减少网络所需要的参数，减少内存和cpu的消耗，使网络更加适应在移动设备上运行。"></a>通过修剪训练后网络中的不重要连接（connections），来减少网络所需要的参数，减少内存和cpu的消耗，使网络更加适应在移动设备上运行。</h2><h1 id="2-idea_u601D_u60F3_uFF1A"><a href="#2-idea_u601D_u60F3_uFF1A" class="headerlink" title="2.idea思想："></a>2.idea思想：</h1><h4 id="1_uFF09_u9996_u5148_u8BAD_u7EC3_u6574_u4E2A_u7F51_u7EDC_uFF0C_u5224_u65AD_u54EA_u4E9B_u662F_u91CD_u8981_u8FDE_u63A5_u3002"><a href="#1_uFF09_u9996_u5148_u8BAD_u7EC3_u6574_u4E2A_u7F51_u7EDC_uFF0C_u5224_u65AD_u54EA_u4E9B_u662F_u91CD_u8981_u8FDE_u63A5_u3002" class="headerlink" title="1）首先训练整个网络，判断哪些是重要连接。"></a>1）首先训练整个网络，判断哪些是重要连接。</h4><h4 id="2_uFF09_u4FEE_u526A_u4E0D_u91CD_u8981_u7684_u8FDE_u63A5_u3002"><a href="#2_uFF09_u4FEE_u526A_u4E0D_u91CD_u8981_u7684_u8FDE_u63A5_u3002" class="headerlink" title="2）修剪不重要的连接。"></a>2）修剪不重要的连接。</h4><h4 id="3_uFF09_u91CD_u65B0_u8BAD_u7EC3_u4FEE_u526A_u540E_u7684_u7F51_u7EDC_uFF0C_u5FAE_u8C03_u4FDD_u7559_u4E0B_u6765_u7684_u53C2_u6570_u3002"><a href="#3_uFF09_u91CD_u65B0_u8BAD_u7EC3_u4FEE_u526A_u540E_u7684_u7F51_u7EDC_uFF0C_u5FAE_u8C03_u4FDD_u7559_u4E0B_u6765_u7684_u53C2_u6570_u3002" class="headerlink" title="3）重新训练修剪后的网络，微调保留下来的参数。"></a>3）重新训练修剪后的网络，微调保留下来的参数。</h4><h1 id="3-_u8FBE_u5230_u7684_u6548_u679C_uFF1A"><a href="#3-_u8FBE_u5230_u7684_u6548_u679C_uFF1A" class="headerlink" title="3.达到的效果："></a>3.达到的效果：</h1><h4 id="1_uFF09_u5728ImageNet_u4E0A_uFF0C_u51CF_u5C11_u4E86AlexNet_9_u500D_u7684_u53C2_u6570_uFF0C_u4ECE61_million_u7684_u53C2_u6570_u51CF_u5C11_u52306-1_million_u7684_u53C2_u6570_uFF1BVGG_u7F51_u7EDC_u5219_u66F4_u662F_u51CF_u5C11_u4E8616_u500D_uFF0C_u5E76_u4E14_u4FEE_u526A_u540E_u7684_u7F51_u8DEF_u7684accuracy_u6CA1_u6709_u4E0B_u964D_u3002"><a href="#1_uFF09_u5728ImageNet_u4E0A_uFF0C_u51CF_u5C11_u4E86AlexNet_9_u500D_u7684_u53C2_u6570_uFF0C_u4ECE61_million_u7684_u53C2_u6570_u51CF_u5C11_u52306-1_million_u7684_u53C2_u6570_uFF1BVGG_u7F51_u7EDC_u5219_u66F4_u662F_u51CF_u5C11_u4E8616_u500D_uFF0C_u5E76_u4E14_u4FEE_u526A_u540E_u7684_u7F51_u8DEF_u7684accuracy_u6CA1_u6709_u4E0B_u964D_u3002" class="headerlink" title="1）在ImageNet上，减少了AlexNet 9倍的参数，从61 million的参数减少到6.1 million的参数；VGG网络则更是减少了16倍，并且修剪后的网路的accuracy没有下降。"></a>1）在ImageNet上，减少了AlexNet 9倍的参数，从61 million的参数减少到6.1 million的参数；VGG网络则更是减少了16倍，并且修剪后的网路的accuracy没有下降。</h4><h4 id="2_uFF09_u53EF_u4EE5_u9632_u6B62_u8FC7_u62DF_u5408"><a href="#2_uFF09_u53EF_u4EE5_u9632_u6B62_u8FC7_u62DF_u5408" class="headerlink" title="2）可以防止过拟合"></a>2）可以防止过拟合</h4><h1 id="4-_u5176_u5B83_u76F8_u5173_u7684_u5DE5_u4F5C_uFF1A"><a href="#4-_u5176_u5B83_u76F8_u5173_u7684_u5DE5_u4F5C_uFF1A" class="headerlink" title="4.其它相关的工作："></a>4.其它相关的工作：</h1><h4 id="1_uFF09_u75288_u4F4Dint_u578B_u7684activation_u4EE3_u66FF16_u4F4Dfloat_u3002"><a href="#1_uFF09_u75288_u4F4Dint_u578B_u7684activation_u4EE3_u66FF16_u4F4Dfloat_u3002" class="headerlink" title="1）用8位int型的activation代替16位float。"></a>1）用8位int型的activation代替16位float。</h4><h4 id="2_uFF09Network_in_Network_u548CGoogleNet_u6A21_u578B_u4E2D_u4F7F_u7528_u4E86global_average_pooling_u4EE3_u66FFFC_u5C42_u6765_u51CF_u5C11_u53C2_u6570_uFF0C_u4F46_u5728_u4F7F_u7528ImageNet_u7684_u53C2_u6570_u65F6_uFF0C_u9700_u8981_u53E6_u5916_u589E_u52A0_u4E00_u4E2A_u7EBF_u6027_u5C42_u3002"><a href="#2_uFF09Network_in_Network_u548CGoogleNet_u6A21_u578B_u4E2D_u4F7F_u7528_u4E86global_average_pooling_u4EE3_u66FFFC_u5C42_u6765_u51CF_u5C11_u53C2_u6570_uFF0C_u4F46_u5728_u4F7F_u7528ImageNet_u7684_u53C2_u6570_u65F6_uFF0C_u9700_u8981_u53E6_u5916_u589E_u52A0_u4E00_u4E2A_u7EBF_u6027_u5C42_u3002" class="headerlink" title="2）Network in Network和GoogleNet模型中使用了global average pooling代替FC层来减少参数，但在使用ImageNet的参数时，需要另外增加一个线性层。"></a>2）Network in Network和GoogleNet模型中使用了global average pooling代替FC层来减少参数，但在使用ImageNet的参数时，需要另外增加一个线性层。</h4><h4 id="3_uFF09dropout_u548C_u672C_u6587_u7684_u65B9_u6CD5_u4E0D_u540C_uFF0Cdropout_u4E3B_u8981_u7528_u6765_u9632_u6B62_u8FC7_u62DF_u5408_uFF0C_u5E76_u4E14_u662F_u5728_u8BAD_u7EC3_u8FC7_u7A0B_u4E2D_u5C31_u4EA7_u751F0_u8FDE_u63A5_uFF0C_u800C_u672C_u6587_u7684_u65B9_u6CD5_u5219_u662F_u5728_u7F51_u7EDC_u8BAD_u7EC3_u5B8C_u4E4B_u540E_u5BF9_u7F51_u7EDC_u8FDB_u884C_u4FEE_u526A_uFF0C_u4EA7_u751F0_u8FDE_u63A5_u3002"><a href="#3_uFF09dropout_u548C_u672C_u6587_u7684_u65B9_u6CD5_u4E0D_u540C_uFF0Cdropout_u4E3B_u8981_u7528_u6765_u9632_u6B62_u8FC7_u62DF_u5408_uFF0C_u5E76_u4E14_u662F_u5728_u8BAD_u7EC3_u8FC7_u7A0B_u4E2D_u5C31_u4EA7_u751F0_u8FDE_u63A5_uFF0C_u800C_u672C_u6587_u7684_u65B9_u6CD5_u5219_u662F_u5728_u7F51_u7EDC_u8BAD_u7EC3_u5B8C_u4E4B_u540E_u5BF9_u7F51_u7EDC_u8FDB_u884C_u4FEE_u526A_uFF0C_u4EA7_u751F0_u8FDE_u63A5_u3002" class="headerlink" title="3）dropout和本文的方法不同，dropout主要用来防止过拟合，并且是在训练过程中就产生0连接，而本文的方法则是在网络训练完之后对网络进行修剪，产生0连接。"></a>3）dropout和本文的方法不同，dropout主要用来防止过拟合，并且是在训练过程中就产生0连接，而本文的方法则是在网络训练完之后对网络进行修剪，产生0连接。</h4><h4 id="4_uFF09HashNet_u8FD9_u4E2A_u672C_u4EBA_u6CA1_u6709_u770B_u8FC7_uFF0C_u8BBA_u6587_u91CC_u4F5C_u8005_u731C_u60F3HashNet_u548Cpruning_u7ED3_u5408_u53EF_u80FD_u6548_u679C_u66F4_u597D_u3002"><a href="#4_uFF09HashNet_u8FD9_u4E2A_u672C_u4EBA_u6CA1_u6709_u770B_u8FC7_uFF0C_u8BBA_u6587_u91CC_u4F5C_u8005_u731C_u60F3HashNet_u548Cpruning_u7ED3_u5408_u53EF_u80FD_u6548_u679C_u66F4_u597D_u3002" class="headerlink" title="4）HashNet这个本人没有看过，论文里作者猜想HashNet和pruning结合可能效果更好。"></a>4）HashNet这个本人没有看过，论文里作者猜想HashNet和pruning结合可能效果更好。</h4><h1 id="5-_u5177_u4F53_u6D41_u7A0B_uFF1A"><a href="#5-_u5177_u4F53_u6D41_u7A0B_uFF1A" class="headerlink" title="5.具体流程："></a>5.具体流程：</h1><h3 id="u9996_u5148_u8BAD_u7EC3_u6574_u4E2A_u7F51_u7EDC_uFF0C_u76EE_u7684_u662F_u627E_u51FA_u54EA_u4E9B_u662F_u91CD_u8981_u7684_u8FDE_u63A5_uFF1B_u63A5_u7740_u8BBE_u7F6E_u4E00_u4E2Athreshold_uFF0Cpruning_u6389low-weight_u7684_u8FDE_u63A5_uFF0C_u5C06_u5BC6_u96C6_u7684_u7F51_u7EDC_u53D8_u6210_u7A00_u758F_u7684_u7F51_u7EDC_uFF1B_u6700_u540E_u5219_u662F_u5BF9_u4F59_u4E0B_u6765_u7684params_u8FDB_u884C_u5FAE_u8C03_uFF0C_u5982_u679C_u4E0D_u5FAE_u8C03_uFF0C_u90A3_u4E48_u5BF9_u7F51_u7EDC_u7684_u6027_u80FD_u4F1A_u6709_u5F88_u5927_u7684_u5F71_u54CD_u3002_u5982_u56FE_uFF1A"><a href="#u9996_u5148_u8BAD_u7EC3_u6574_u4E2A_u7F51_u7EDC_uFF0C_u76EE_u7684_u662F_u627E_u51FA_u54EA_u4E9B_u662F_u91CD_u8981_u7684_u8FDE_u63A5_uFF1B_u63A5_u7740_u8BBE_u7F6E_u4E00_u4E2Athreshold_uFF0Cpruning_u6389low-weight_u7684_u8FDE_u63A5_uFF0C_u5C06_u5BC6_u96C6_u7684_u7F51_u7EDC_u53D8_u6210_u7A00_u758F_u7684_u7F51_u7EDC_uFF1B_u6700_u540E_u5219_u662F_u5BF9_u4F59_u4E0B_u6765_u7684params_u8FDB_u884C_u5FAE_u8C03_uFF0C_u5982_u679C_u4E0D_u5FAE_u8C03_uFF0C_u90A3_u4E48_u5BF9_u7F51_u7EDC_u7684_u6027_u80FD_u4F1A_u6709_u5F88_u5927_u7684_u5F71_u54CD_u3002_u5982_u56FE_uFF1A" class="headerlink" title="首先训练整个网络，目的是找出哪些是重要的连接；接着设置一个threshold，pruning掉low-weight的连接，将密集的网络变成稀疏的网络；最后则是对余下来的params进行微调，如果不微调，那么对网络的性能会有很大的影响。如图："></a>首先训练整个网络，目的是找出哪些是重要的连接；接着设置一个threshold，pruning掉low-weight的连接，将密集的网络变成稀疏的网络；最后则是对余下来的params进行微调，如果不微调，那么对网络的性能会有很大的影响。如图：</h3><p><img src="http://img.blog.csdn.net/20150924170455546" alt="这里写图片描述"></p>
<h3 id="u800C_u4F7F_u7528_u672C_u6587_u7684_u65B9_u6CD5_u9700_u8981_u5F88_u5927_u7684_u6280_u5DE7_u6027_uFF1A"><a href="#u800C_u4F7F_u7528_u672C_u6587_u7684_u65B9_u6CD5_u9700_u8981_u5F88_u5927_u7684_u6280_u5DE7_u6027_uFF1A" class="headerlink" title="而使用本文的方法需要很大的技巧性："></a>而使用本文的方法需要很大的技巧性：</h3><h4 id="1_uFF09Regularization_uFF1A_u9700_u8981_u9009_u62E9_u5408_u9002_u7684regularization_u3002L1_u8303_u5F0F_u4F1A_u5C06_u66F4_u591A_u7684params_u8F6C_u6362_u6210_u63A5_u8FD10_uFF0C_u8FD9_u5728_u8FDB_u884Cpruning_u4E4B_u540E_uFF0CreTrain_u4E4B_u524D_u6709_u5F88_u597D_u7684accuracy_uFF1BL2_u8303_u5F0F_u5728pruning_u548CreTrain_u4E4B_u540E_u4F1A_u964D_u4F4Eaccuracy_u3002"><a href="#1_uFF09Regularization_uFF1A_u9700_u8981_u9009_u62E9_u5408_u9002_u7684regularization_u3002L1_u8303_u5F0F_u4F1A_u5C06_u66F4_u591A_u7684params_u8F6C_u6362_u6210_u63A5_u8FD10_uFF0C_u8FD9_u5728_u8FDB_u884Cpruning_u4E4B_u540E_uFF0CreTrain_u4E4B_u524D_u6709_u5F88_u597D_u7684accuracy_uFF1BL2_u8303_u5F0F_u5728pruning_u548CreTrain_u4E4B_u540E_u4F1A_u964D_u4F4Eaccuracy_u3002" class="headerlink" title="1）Regularization：需要选择合适的regularization。L1范式会将更多的params转换成接近0，这在进行pruning之后，reTrain之前有很好的accuracy；L2范式在pruning和reTrain之后会降低accuracy。"></a>1）Regularization：需要选择合适的regularization。L1范式会将更多的params转换成接近0，这在进行pruning之后，reTrain之前有很好的accuracy；L2范式在pruning和reTrain之后会降低accuracy。</h4><h4 id="2_uFF09Dropout_and_capacity_control_uFF1Adropout_u88AB_u5F53_u505A_u201Csoft_dropout_u201D_uFF0C_u800C_u672C_u6587_u7684_u65B9_u6CD5_u5219_u88AB_u5F53_u505A_u201Chard_dropout_u201D_uFF1B_u8FD9_u662F_u56E0_u4E3Adropout_u4E2D_u88ABdrop_u7684_u5728_u65B0_u7684_u8BAD_u7EC3_u6279_u65F6_uFF0C_u53EF_u4EE5_u88AB_u91CD_u65B0_u8BAD_u7EC3_uFF1B_u800C_u672C_u6587_u7684_u5219_u662F_u76F4_u63A5_u53BB_u6389_u8FDE_u63A5connections_u3002_u800C_u5728_u4F7F_u7528_u672C_u6587_u65B9_u6CD5_u7684_u65F6_u5019_uFF0Cdropout_u7684ratio_u4E5F_u5206pruning_u4E4B_u524D_u548Cpruning_u4E0D_u4E00_u6837_uFF0C_u5177_u4F53_u5982_u56FE_u6240_u793A_uFF1A"><a href="#2_uFF09Dropout_and_capacity_control_uFF1Adropout_u88AB_u5F53_u505A_u201Csoft_dropout_u201D_uFF0C_u800C_u672C_u6587_u7684_u65B9_u6CD5_u5219_u88AB_u5F53_u505A_u201Chard_dropout_u201D_uFF1B_u8FD9_u662F_u56E0_u4E3Adropout_u4E2D_u88ABdrop_u7684_u5728_u65B0_u7684_u8BAD_u7EC3_u6279_u65F6_uFF0C_u53EF_u4EE5_u88AB_u91CD_u65B0_u8BAD_u7EC3_uFF1B_u800C_u672C_u6587_u7684_u5219_u662F_u76F4_u63A5_u53BB_u6389_u8FDE_u63A5connections_u3002_u800C_u5728_u4F7F_u7528_u672C_u6587_u65B9_u6CD5_u7684_u65F6_u5019_uFF0Cdropout_u7684ratio_u4E5F_u5206pruning_u4E4B_u524D_u548Cpruning_u4E0D_u4E00_u6837_uFF0C_u5177_u4F53_u5982_u56FE_u6240_u793A_uFF1A" class="headerlink" title="2）Dropout and capacity control：dropout被当做“soft dropout”，而本文的方法则被当做“hard dropout”；这是因为dropout中被drop的在新的训练批时，可以被重新训练；而本文的则是直接去掉连接connections。而在使用本文方法的时候，dropout的ratio也分pruning之前和pruning不一样，具体如图所示："></a>2）Dropout and capacity control：dropout被当做“soft dropout”，而本文的方法则被当做“hard dropout”；这是因为dropout中被drop的在新的训练批时，可以被重新训练；而本文的则是直接去掉连接connections。而在使用本文方法的时候，dropout的ratio也分pruning之前和pruning不一样，具体如图所示：</h4><p><img src="http://img.blog.csdn.net/20150925165024751" alt="这里写图片描述"></p>
<h4 id="3_uFF09Local_Pruning_and_Parameter_Co-adaptation_uFF1A_u5728reTrain_u7684_u8FC7_u7A0B_u4E2D_uFF0C_u91CD_u65B0_u8BAD_u7EC3pruning_u540E_u4FDD_u5B58_u4E0B_u6765_u7684weights_u6BD4_u8BAD_u7EC3_u518D_u6B21_u521D_u59CB_u5316_u7684weights_u66F4_u597D_u3002_u5176_u6B21_uFF0C_u4E3A_u4E86_u514B_u670Dvanish_gradient_problem_u7684_u95EE_u9898_uFF0C_u4F5C_u8005_u53EA_u8BAD_u7EC3pruning_u540Eshallow_layer_u4FDD_u5B58_u4E0B_u6765_u7684params_u3002"><a href="#3_uFF09Local_Pruning_and_Parameter_Co-adaptation_uFF1A_u5728reTrain_u7684_u8FC7_u7A0B_u4E2D_uFF0C_u91CD_u65B0_u8BAD_u7EC3pruning_u540E_u4FDD_u5B58_u4E0B_u6765_u7684weights_u6BD4_u8BAD_u7EC3_u518D_u6B21_u521D_u59CB_u5316_u7684weights_u66F4_u597D_u3002_u5176_u6B21_uFF0C_u4E3A_u4E86_u514B_u670Dvanish_gradient_problem_u7684_u95EE_u9898_uFF0C_u4F5C_u8005_u53EA_u8BAD_u7EC3pruning_u540Eshallow_layer_u4FDD_u5B58_u4E0B_u6765_u7684params_u3002" class="headerlink" title="3）Local Pruning and Parameter Co-adaptation：在reTrain的过程中，重新训练pruning后保存下来的weights比训练再次初始化的weights更好。其次，为了克服vanish gradient problem的问题，作者只训练pruning后shallow layer保存下来的params。"></a>3）Local Pruning and Parameter Co-adaptation：在reTrain的过程中，重新训练pruning后保存下来的weights比训练再次初始化的weights更好。其次，为了克服vanish gradient problem的问题，作者只训练pruning后shallow layer保存下来的params。</h4><h4 id="4_uFF09Iterative_Pruning_3A_u5176_u5B9E_u5C31_u662F_u91CD_u590D_u7684pruning_uFF0C_u53CD_u590D_u7684_u627E_u51FA_u4E0D_u91CD_u8981_u7684_u8FDE_u63A5_u7136_u540Epruning_u3002"><a href="#4_uFF09Iterative_Pruning_3A_u5176_u5B9E_u5C31_u662F_u91CD_u590D_u7684pruning_uFF0C_u53CD_u590D_u7684_u627E_u51FA_u4E0D_u91CD_u8981_u7684_u8FDE_u63A5_u7136_u540Epruning_u3002" class="headerlink" title="4）Iterative Pruning:其实就是重复的pruning，反复的找出不重要的连接然后pruning。"></a>4）Iterative Pruning:其实就是重复的pruning，反复的找出不重要的连接然后pruning。</h4><h4 id="5_uFF09Pruning_Neurons_uFF1A_u4E00_u4E9B0_u8F93_u5165_u6216_u80050_u8F93_u51FA_u7684_neurons_u4E5F_u80FD_u88ABpruned_u3002"><a href="#5_uFF09Pruning_Neurons_uFF1A_u4E00_u4E9B0_u8F93_u5165_u6216_u80050_u8F93_u51FA_u7684_neurons_u4E5F_u80FD_u88ABpruned_u3002" class="headerlink" title="5）Pruning Neurons：一些0输入或者0输出的 neurons也能被pruned。"></a>5）Pruning Neurons：一些0输入或者0输出的 neurons也能被pruned。</h4><p><strong>本文系作者原创，转载请先联系作者: 18254275587@163.com</strong></p>

            
          </span>
        
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2015/10/04/papers/network-in-network-e8-ae-ba-e6-96-87-e7-ac-94-e8-ae-b0/" itemprop="url">
                  Network in Network -- 论文笔记
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            發表於
            <time itemprop="dateCreated" datetime="2015-10-04T19:29:34+08:00" content="2015-10-04">
              2015-10-04
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp; 分類於
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/papers/" itemprop="url" rel="index">
                    <span itemprop="name">papers</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

        </div>
      </header>
    


    <div class="post-body">

      
      

      
        
          <span itemprop="articleBody">
            
              <h1 id="1-_u6982_u8FF0_uFF1A"><a href="#1-_u6982_u8FF0_uFF1A" class="headerlink" title="1.概述："></a>1.概述：</h1><p><img src="http://img.blog.csdn.net/20150926212521249" alt="这里写图片描述"></p>
<h3 id="u4F5C_u8005_u7684_u60F3_u6CD5_u5C31_u662F_u5C06ConVNet_u7684filter_u7528micro_network_u4EE3_u66FF_uFF0CFC_u5C42_u7528global_average_pooling_u4EE3_u66FF_u3002_u8FD9_u6837_u505A_u7684_u597D_u5904_u5C31_u662F_uFF0Cmicro_network_u6BD4filter_u80FD_u63D0_u53D6_u5230_u66F4_u52A0_u62BD_u8C61_u7684_u7279_u5F81_uFF0Cglobal_average_polling_u6CA1_u6709_u53C2_u6570_uFF0C_u76F8_u6BD4_u4E8EFC_uFF0C_u80FD_u591F_u6D88_u9664FC_u5C42_u5E26_u6765_u7684overfitting_u7684_u5F71_u54CD_u3002"><a href="#u4F5C_u8005_u7684_u60F3_u6CD5_u5C31_u662F_u5C06ConVNet_u7684filter_u7528micro_network_u4EE3_u66FF_uFF0CFC_u5C42_u7528global_average_pooling_u4EE3_u66FF_u3002_u8FD9_u6837_u505A_u7684_u597D_u5904_u5C31_u662F_uFF0Cmicro_network_u6BD4filter_u80FD_u63D0_u53D6_u5230_u66F4_u52A0_u62BD_u8C61_u7684_u7279_u5F81_uFF0Cglobal_average_polling_u6CA1_u6709_u53C2_u6570_uFF0C_u76F8_u6BD4_u4E8EFC_uFF0C_u80FD_u591F_u6D88_u9664FC_u5C42_u5E26_u6765_u7684overfitting_u7684_u5F71_u54CD_u3002" class="headerlink" title="作者的想法就是将ConVNet的filter用micro network代替，FC层用global average pooling代替。这样做的好处就是，micro network比filter能提取到更加抽象的特征，global average polling没有参数，相比于FC，能够消除FC层带来的overfitting的影响。"></a>作者的想法就是将ConVNet的filter用micro network代替，FC层用global average pooling代替。这样做的好处就是，micro network比filter能提取到更加抽象的特征，global average polling没有参数，相比于FC，能够消除FC层带来的overfitting的影响。</h3><h1 id="2-idea_uFF1A"><a href="#2-idea_uFF1A" class="headerlink" title="2.idea："></a>2.idea：</h1><h4 id="1_uFF09_uFF1AMLP_Convolution_Layers_uFF1A_u5C31_u662F_u4E00_u4E2A_u7B80_u5355_u7684_u591A_u5C42_u611F_u77E5_u673A_uFF0C_u7528_u6765_u53D6_u4EE3_u4F20_u7EDFConVNet_u7684filter_uFF1A"><a href="#1_uFF09_uFF1AMLP_Convolution_Layers_uFF1A_u5C31_u662F_u4E00_u4E2A_u7B80_u5355_u7684_u591A_u5C42_u611F_u77E5_u673A_uFF0C_u7528_u6765_u53D6_u4EE3_u4F20_u7EDFConVNet_u7684filter_uFF1A" class="headerlink" title="1）：MLP Convolution Layers：就是一个简单的多层感知机，用来取代传统ConVNet的filter："></a>1）：MLP Convolution Layers：就是一个简单的多层感知机，用来取代传统ConVNet的filter：</h4><p><img src="http://img.blog.csdn.net/20150926214017847" alt="这里写图片描述"></p>
<h4 id="2_uFF09global_average_pooling_uFF1A_u7528_u6765_u4EE3_u66FF_u4F20_u7EDFConVNet_u7684FC_u5C42_u3002_u5728_u6700_u540E_u4E00_u4E2Afeature_map_u5C42_u4E0A_uFF0C_u5BF9_u6BCF_u4E2Afeature_map_u5206_u522B_u53D6_u5747_u503C_uFF0C_u7136_u540E_u8FDE_u63A5_u6210_u4E00_u4E2A_u5411_u91CF_u540E_uFF0C_u8F93_u5165softmax_u5206_u7C7B_u5668_u3002global_average_pooling_u4E5F_u53EF_u4EE5_u5F53_u505A_u4E00_u4E2A_u5F88_u597D_u5730regularilizer_uFF1A"><a href="#2_uFF09global_average_pooling_uFF1A_u7528_u6765_u4EE3_u66FF_u4F20_u7EDFConVNet_u7684FC_u5C42_u3002_u5728_u6700_u540E_u4E00_u4E2Afeature_map_u5C42_u4E0A_uFF0C_u5BF9_u6BCF_u4E2Afeature_map_u5206_u522B_u53D6_u5747_u503C_uFF0C_u7136_u540E_u8FDE_u63A5_u6210_u4E00_u4E2A_u5411_u91CF_u540E_uFF0C_u8F93_u5165softmax_u5206_u7C7B_u5668_u3002global_average_pooling_u4E5F_u53EF_u4EE5_u5F53_u505A_u4E00_u4E2A_u5F88_u597D_u5730regularilizer_uFF1A" class="headerlink" title="2）global average pooling：用来代替传统ConVNet的FC层。在最后一个feature map层上，对每个feature map分别取均值，然后连接成一个向量后，输入softmax分类器。global average pooling也可以当做一个很好地regularilizer："></a>2）global average pooling：用来代替传统ConVNet的FC层。在最后一个feature map层上，对每个feature map分别取均值，然后连接成一个向量后，输入softmax分类器。global average pooling也可以当做一个很好地regularilizer：</h4><p><img src="http://img.blog.csdn.net/20150926214932999" alt="这里写图片描述"></p>
<h4 id="3_uFF09_u53EF_u4EE5_u50CF_u4F20_u7EDF_u7684ConVNet_u4E00_u6837_uFF0C_u8BBE_u7F6E_u6BCF_u4E00_u5C42micro_network_u7684_u4E2A_u6570_uFF0C_u4E5F_u53EF_u4EE5_u8BBE_u7F6Emicro_network_u7684_u5C42_u6570_u548C_u9690_u542B_u5C42_u795E_u7ECF_u5143_u7684_u4E2A_u6570_u3002"><a href="#3_uFF09_u53EF_u4EE5_u50CF_u4F20_u7EDF_u7684ConVNet_u4E00_u6837_uFF0C_u8BBE_u7F6E_u6BCF_u4E00_u5C42micro_network_u7684_u4E2A_u6570_uFF0C_u4E5F_u53EF_u4EE5_u8BBE_u7F6Emicro_network_u7684_u5C42_u6570_u548C_u9690_u542B_u5C42_u795E_u7ECF_u5143_u7684_u4E2A_u6570_u3002" class="headerlink" title="3）可以像传统的ConVNet一样，设置每一层micro network的个数，也可以设置micro network的层数和隐含层神经元的个数。"></a>3）可以像传统的ConVNet一样，设置每一层micro network的个数，也可以设置micro network的层数和隐含层神经元的个数。</h4><h1 id="3-_u5B9E_u9A8C_u7ED3_u679C_uFF1A"><a href="#3-_u5B9E_u9A8C_u7ED3_u679C_uFF1A" class="headerlink" title="3.实验结果："></a>3.实验结果：</h1><h4 id="1_uFF09_u4E00_u4E9B_u6570_u636E_u96C6_u7684_u6D4B_u8BD5_u7ED3_u679C_uFF1A"><a href="#1_uFF09_u4E00_u4E9B_u6570_u636E_u96C6_u7684_u6D4B_u8BD5_u7ED3_u679C_uFF1A" class="headerlink" title="1）一些数据集的测试结果："></a>1）一些数据集的测试结果：</h4><p><img src="http://img.blog.csdn.net/20150926215533133" alt="这里写图片描述"><br><img src="http://img.blog.csdn.net/20150926215549871" alt="这里写图片描述"><br><img src="http://img.blog.csdn.net/20150926215608496" alt="这里写图片描述"><br><img src="http://img.blog.csdn.net/20150926215623916" alt="这里写图片描述"></p>
<h4 id="2_uFF09_u4F5C_u8005_u4E5F_u5C06NIN_u7F51_u7EDC_u4E2D_u6700_u540E_u4E00_u5C42feature_map_u8FDB_u884C_u53EF_u89C6_u5316_uFF0C_u8BC1_u660ENIN_u6709_u5F88_u5F3A_u7684_u5C40_u90E8_u611F_u53D7_u91CE_u5EFA_u6A21_u80FD_u529B_uFF08top10_u7684feature_map_uFF09_uFF1A"><a href="#2_uFF09_u4F5C_u8005_u4E5F_u5C06NIN_u7F51_u7EDC_u4E2D_u6700_u540E_u4E00_u5C42feature_map_u8FDB_u884C_u53EF_u89C6_u5316_uFF0C_u8BC1_u660ENIN_u6709_u5F88_u5F3A_u7684_u5C40_u90E8_u611F_u53D7_u91CE_u5EFA_u6A21_u80FD_u529B_uFF08top10_u7684feature_map_uFF09_uFF1A" class="headerlink" title="2）作者也将NIN网络中最后一层feature map进行可视化，证明NIN有很强的局部感受野建模能力（top10的feature map）："></a>2）作者也将NIN网络中最后一层feature map进行可视化，证明NIN有很强的局部感受野建模能力（top10的feature map）：</h4><p><img src="http://img.blog.csdn.net/20150926215928922" alt="这里写图片描述"></p>
<p><strong>本文系作者原创，转载请先联系作者: 18254275587@163.com</strong></p>

            
          </span>
        
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2015/10/04/papers/prelu-delving-deep-into-rectifiers-surpassing-human-level-performance-on-imagenet-classification/" itemprop="url">
                  PRelu--Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            發表於
            <time itemprop="dateCreated" datetime="2015-10-04T19:27:50+08:00" content="2015-10-04">
              2015-10-04
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp; 分類於
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/papers/" itemprop="url" rel="index">
                    <span itemprop="name">papers</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

        </div>
      </header>
    


    <div class="post-body">

      
      

      
        
          <span itemprop="articleBody">
            
              <p>微软研究院2015的一篇论文。</p>
<h1 id="1-_u6982_u8981_uFF1A"><a href="#1-_u6982_u8981_uFF1A" class="headerlink" title="1.概要："></a>1.概要：</h1><h4 id="PRelu_u5176_u5B9E_u662FRelu_u7684_u589E_u5F3A_u7248_uFF0CPRelu_u4F7F_u5F97_u6A21_u578B_u5728ImageNet2012_u4E0A_u7684_u7ED3_u679C_u63D0_u9AD8_u52304-94_25_uFF0C_u8D85_u8FC7_u666E_u901A_u4EBA_u7684_u6B63_u786E_u7387_uFF1BPRelu_u9700_u8981_u50CF_u66F4_u65B0_u6743_u91CDweights_u4E00_u6837_u4F7F_u7528BP_u66F4_u65B0_u4E00_u4E2A_u989D_u5916_u7684_u53C2_u6570_uFF0C_u4F46_u662F_u76F8_u8F83_u4E8Eweights_u7684_u6570_u91CF_u6765_u8BF4_uFF0CPRelu_u9700_u8981_u66F4_u65B0_u7684_u53C2_u6570_u603B_u6570_u53EF_u4EE5_u5FFD_u7565_u4E0D_u8BA1_uFF0C_u6240_u4EE5_u4E0D_u4F1A_u52A0_u91CDoverfitting_u7684_u5F71_u54CD_u3002"><a href="#PRelu_u5176_u5B9E_u662FRelu_u7684_u589E_u5F3A_u7248_uFF0CPRelu_u4F7F_u5F97_u6A21_u578B_u5728ImageNet2012_u4E0A_u7684_u7ED3_u679C_u63D0_u9AD8_u52304-94_25_uFF0C_u8D85_u8FC7_u666E_u901A_u4EBA_u7684_u6B63_u786E_u7387_uFF1BPRelu_u9700_u8981_u50CF_u66F4_u65B0_u6743_u91CDweights_u4E00_u6837_u4F7F_u7528BP_u66F4_u65B0_u4E00_u4E2A_u989D_u5916_u7684_u53C2_u6570_uFF0C_u4F46_u662F_u76F8_u8F83_u4E8Eweights_u7684_u6570_u91CF_u6765_u8BF4_uFF0CPRelu_u9700_u8981_u66F4_u65B0_u7684_u53C2_u6570_u603B_u6570_u53EF_u4EE5_u5FFD_u7565_u4E0D_u8BA1_uFF0C_u6240_u4EE5_u4E0D_u4F1A_u52A0_u91CDoverfitting_u7684_u5F71_u54CD_u3002" class="headerlink" title="PRelu其实是Relu的增强版，PRelu使得模型在ImageNet2012上的结果提高到4.94%，超过普通人的正确率；PRelu需要像更新权重weights一样使用BP更新一个额外的参数，但是相较于weights的数量来说，PRelu需要更新的参数总数可以忽略不计，所以不会加重overfitting的影响。"></a>PRelu其实是Relu的增强版，PRelu使得模型在ImageNet2012上的结果提高到4.94%，超过普通人的正确率；PRelu需要像更新权重weights一样使用BP更新一个额外的参数，但是相较于weights的数量来说，PRelu需要更新的参数总数可以忽略不计，所以不会加重overfitting的影响。</h4><h4 id="u5982_u679CPRelu_u7684_u53C2_u6570_u4E3A0_uFF0C_u90A3_u5176_u5B9E_u5C31_u662FRelu_uFF1B_u5982_u679CPRelu_u7684_u53C2_u6570_u4E3A_u4E00_u4E2A_u5F88_u5C0F_u7684_u5E38_u6570constant_uFF0C_u6BD4_u59820-01_2C_u90A3_u5176_u5B9E_u5C31_u662FLeaky_Relu_28LRelu_29_u3002"><a href="#u5982_u679CPRelu_u7684_u53C2_u6570_u4E3A0_uFF0C_u90A3_u5176_u5B9E_u5C31_u662FRelu_uFF1B_u5982_u679CPRelu_u7684_u53C2_u6570_u4E3A_u4E00_u4E2A_u5F88_u5C0F_u7684_u5E38_u6570constant_uFF0C_u6BD4_u59820-01_2C_u90A3_u5176_u5B9E_u5C31_u662FLeaky_Relu_28LRelu_29_u3002" class="headerlink" title="如果PRelu的参数为0，那其实就是Relu；如果PRelu的参数为一个很小的常数constant，比如0.01,那其实就是Leaky Relu(LRelu)。"></a>如果PRelu的参数为0，那其实就是Relu；如果PRelu的参数为一个很小的常数constant，比如0.01,那其实就是Leaky Relu(LRelu)。</h4><h4 id="Relu_u4E0EPRelu_u7684_u6BD4_u8F83_uFF1A"><a href="#Relu_u4E0EPRelu_u7684_u6BD4_u8F83_uFF1A" class="headerlink" title="Relu与PRelu的比较："></a>Relu与PRelu的比较：</h4><p><img src="http://img.blog.csdn.net/20150928190107016" alt="这里写图片描述"></p>
<h4 id="PRelu_u7684_u8868_u8FBE_u5F0F_uFF1A"><a href="#PRelu_u7684_u8868_u8FBE_u5F0F_uFF1A" class="headerlink" title="PRelu的表达式："></a>PRelu的表达式：</h4><p><img src="http://img.blog.csdn.net/20150928190132211" alt="这里写图片描述"></p>
<h1 id="2-idea_uFF1A"><a href="#2-idea_uFF1A" class="headerlink" title="2.idea："></a>2.idea：</h1><h4 id="1_29_3A__u6BCF_u4E00_u4E2Afeature_map_uFF08CNN_uFF09_u5BF9_u5E94_u7684PRelu_u7684_u7CFB_u6570_u90FD_u53EF_u4EE5_u662F_u4E0D_u540C_u7684_2C_u4E5F_u53EF_u4EE5_u662F_u76F8_u540C_u5C42_u7684PRelu_u7684_u7CFB_u6570_u90FD_u4E00_u6837_uFF0C_u5C42_u95F4_u4E0D_u540C_u3002"><a href="#1_29_3A__u6BCF_u4E00_u4E2Afeature_map_uFF08CNN_uFF09_u5BF9_u5E94_u7684PRelu_u7684_u7CFB_u6570_u90FD_u53EF_u4EE5_u662F_u4E0D_u540C_u7684_2C_u4E5F_u53EF_u4EE5_u662F_u76F8_u540C_u5C42_u7684PRelu_u7684_u7CFB_u6570_u90FD_u4E00_u6837_uFF0C_u5C42_u95F4_u4E0D_u540C_u3002" class="headerlink" title="1): 每一个feature map（CNN）对应的PRelu的系数都可以是不同的,也可以是相同层的PRelu的系数都一样，层间不同。"></a>1): 每一个feature map（CNN）对应的PRelu的系数都可以是不同的,也可以是相同层的PRelu的系数都一样，层间不同。</h4><h4 id="2_29_3A__u4F5C_u8005_u5728_u5B9E_u9A8C_u7684_u65F6_u5019_u90FD_u662F_u5C06_u7CFB_u6570_u521D_u59CB_u5316_u4E3A0-25"><a href="#2_29_3A__u4F5C_u8005_u5728_u5B9E_u9A8C_u7684_u65F6_u5019_u90FD_u662F_u5C06_u7CFB_u6570_u521D_u59CB_u5316_u4E3A0-25" class="headerlink" title="2): 作者在实验的时候都是将系数初始化为0.25"></a>2): 作者在实验的时候都是将系数初始化为0.25</h4><h4 id="3_29_3A__u4F18_u5316_u7684_u65F6_u5019_u4E0D_u4F1A_u5BF9PRelu_u7684_u7CFB_u6570_u8FDB_u884Cregularization_uFF0C_u5426_u5219_u4F1A_u8BA9_u7CFB_u6570_u8D8B_u8FD1_u4E8E0_uFF0C_u57FA_u672C_u76F8_u5F53_u4E8ELRelu_u6216_u8005Relu_u4E86_u3002"><a href="#3_29_3A__u4F18_u5316_u7684_u65F6_u5019_u4E0D_u4F1A_u5BF9PRelu_u7684_u7CFB_u6570_u8FDB_u884Cregularization_uFF0C_u5426_u5219_u4F1A_u8BA9_u7CFB_u6570_u8D8B_u8FD1_u4E8E0_uFF0C_u57FA_u672C_u76F8_u5F53_u4E8ELRelu_u6216_u8005Relu_u4E86_u3002" class="headerlink" title="3): 优化的时候不会对PRelu的系数进行regularization，否则会让系数趋近于0，基本相当于LRelu或者Relu了。"></a>3): 优化的时候不会对PRelu的系数进行regularization，否则会让系数趋近于0，基本相当于LRelu或者Relu了。</h4><h1 id="3-_u6D41_u7A0B_uFF1A"><a href="#3-_u6D41_u7A0B_uFF1A" class="headerlink" title="3.流程："></a>3.流程：</h1><h4 id="PRelu_u7684_u7CFB_u6570_u4E5F_u662F_u5728BP_u7684_u65F6_u5019_u8FDB_u884C_u4F18_u5316_u7684_uFF0C_u4E0Eweights_u7684_u65B9_u5F0F_u4E00_u6837"><a href="#PRelu_u7684_u7CFB_u6570_u4E5F_u662F_u5728BP_u7684_u65F6_u5019_u8FDB_u884C_u4F18_u5316_u7684_uFF0C_u4E0Eweights_u7684_u65B9_u5F0F_u4E00_u6837" class="headerlink" title="PRelu的系数也是在BP的时候进行优化的，与weights的方式一样"></a>PRelu的系数也是在BP的时候进行优化的，与weights的方式一样</h4><h4 id="u76EE_u6807_u51FD_u6570_u5BF9PRelu_u7684_u7CFB_u6570_u6C42_u504F_u5BFC_uFF1A"><a href="#u76EE_u6807_u51FD_u6570_u5BF9PRelu_u7684_u7CFB_u6570_u6C42_u504F_u5BFC_uFF1A" class="headerlink" title="目标函数对PRelu的系数求偏导："></a>目标函数对PRelu的系数求偏导：</h4><p><img src="http://img.blog.csdn.net/20150928191127468" alt="这里写图片描述"></p>
<h4 id="u4F18_u5316_uFF1A"><a href="#u4F18_u5316_uFF1A" class="headerlink" title="优化："></a>优化：</h4><p><img src="http://img.blog.csdn.net/20150928191206609" alt="这里写图片描述"></p>
<h1 id="4-_u4EE3_u7801_uFF08keras_uFF09_uFF1A"><a href="#4-_u4EE3_u7801_uFF08keras_uFF09_uFF1A" class="headerlink" title="4.代码（keras）："></a>4.代码（keras）：</h1><pre><code>def __init__(self, input_shape, init=&amp;#039;zero&amp;#039;, weights=None):
    super(PReLU, self).__init__()
    self.init = initializations.get(init)
    self.alphas = self.init(input_shape)
    self.params = [self.alphas]
    self.input_shape = input_shape

    if weights is not None:
        self.set_weights(weights)

def get_output(self, train):
    X = self.get_input(train)
    pos = ((X + abs(X)) / 2.0)
    neg = self.alphas * ((X - abs(X)) / 2.0)
    return pos + neg

def get_config(self):
    return {&amp;quot;name&amp;quot;: self.__class__.__name__,
            &amp;quot;input_shape&amp;quot;: self.input_shape,
            &amp;quot;init&amp;quot;: self.init.__name__}
</code></pre><p><strong>本文系作者原创，转载请先联系作者: 18254275587@163.com</strong></p>

            
          </span>
        
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    

  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/2/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/">2</a><span class="page-number current">3</span><a class="page-number" href="/page/4/">4</a><a class="extend next" rel="next" href="/page/4/"><i class="fa fa-angle-right"></i></a>
  </nav>



        </div>

        


        

      </div>

      
        
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <section class="site-overview sidebar-panel  sidebar-panel-active ">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" src="/images/default_avatar.jpg" alt="John Doe" itemprop="image"/>
          <p class="site-author-name" itemprop="name">John Doe</p>
        </div>
        <p class="site-description motion-element" itemprop="description"></p>
        <nav class="site-state motion-element">
          <div class="site-state-item site-state-posts">
            <a href="/archives">
              <span class="site-state-item-count">31</span>
              <span class="site-state-item-name">文章</span>
            </a>
          </div>

          <div class="site-state-item site-state-categories">
            
              <span class="site-state-item-count">5</span>
              <span class="site-state-item-name">分類</span>
              
          </div>

          <div class="site-state-item site-state-tags">
            <a href="/tags">
              <span class="site-state-item-count">0</span>
              <span class="site-state-item-name">標籤</span>
              </a>
          </div>

        </nav>

        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        <div class="links-of-author motion-element">
          
        </div>

      </section>

      

    </div>
  </aside>


      
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2015</span>
  <span class="with-love">
    <i class="icon-next-heart fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">John Doe</span>
</div>

<div class="powered-by">
  由 <a class="theme-link" href="http://hexo.io">Hexo</a> 強力驅動
</div>

<div class="theme-info">
  主題 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT
  </a>
</div>



      </div>
    </footer>

    <div class="back-to-top"></div>
  </div>

  <script type="text/javascript" src="/vendors/jquery/index.js?v=2.1.3"></script>

  
  

  
    
    

  


  

  
  <script type="text/javascript" src="/vendors/fancybox/source/jquery.fancybox.pack.js"></script>
  <script type="text/javascript" src="/js/fancy-box.js?v=0.4.5.2"></script>


  <script type="text/javascript" src="/js/helpers.js?v=0.4.5.2"></script>
  <script type="text/javascript" src="/vendors/velocity/velocity.min.js"></script>
<script type="text/javascript" src="/vendors/velocity/velocity.ui.min.js"></script>

<script type="text/javascript" src="/js/motion.js?v=0.4.5.2" id="motion.global"></script>


  <script type="text/javascript" src="/vendors/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  <script type="text/javascript" src="/vendors/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  

  <script type="text/javascript" src="/js/bootstrap.js"></script>

  
  

  
  

</body>
</html>
